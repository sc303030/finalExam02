{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProjectCode",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "syKBTnSO7j4B"
      },
      "source": [
        "pip install xlsxwriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0_QXUnx7pXi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import sys\n",
        "from openpyxl import load_workbook\n",
        "import xlsxwriter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuYkaitW7qfw"
      },
      "source": [
        "# 코랩 한글깨짐 설정\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kP21uQ37uqX"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx_F9jl7Mlxk"
      },
      "source": [
        "# 구 별 품목별 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1SKj7s07yY4"
      },
      "source": [
        "data=pd.read_excel('/content/서울전역시장마트데이터(구분포함,23월포함).xlsx')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeW1V4AS8Pmk"
      },
      "source": [
        "def For_product(data1, data2, data3, product) :\n",
        "    cols = ['단위', '비고', '지역구', '장소','구분']\n",
        "    name = ['시장', '마트', '서울']\n",
        "  \n",
        "    test_i = data1[data1['품목']==product]\n",
        "    test_a = test_i.drop(cols, axis=1)\n",
        "    test_a = test_a.groupby('조사일')['가격'].mean().reset_index()\n",
        "    test_a = test_a.set_index('조사일')\n",
        "    y_test = test_a['가격'].resample('MS').mean()\n",
        "    y_test = y_test['2017' : ]\n",
        "    y = pd.DataFrame(y_test)\n",
        "\n",
        "    test_0_i = data2[data2['품목']==product]\n",
        "    test_0_a = test_0_i.drop(cols, axis=1)\n",
        "    test_0_a = test_0_a.groupby('조사일')['가격'].mean().reset_index()\n",
        "    test_0_a = test_0_a.set_index('조사일')\n",
        "    x_test = test_0_a['가격'].resample('MS').mean()\n",
        "    x_test=x_test['2017' :]\n",
        "    x = pd.DataFrame(x_test)\n",
        "    \n",
        "    seoul = data3[data3['품목']==product]\n",
        "    seoul = seoul.drop(cols, axis=1)\n",
        "    seoul = seoul.groupby('조사일')['가격'].mean().reset_index()\n",
        "    seoul = seoul.set_index('조사일')\n",
        "    seoul = seoul['가격'].resample('MS').mean()\n",
        "    seoul = seoul['2017' : ]\n",
        "    z = pd.DataFrame(seoul)\n",
        "\n",
        "    do_merge = y.merge(x,on='조사일').merge(z,on='조사일')\n",
        "    do_merge.columns = name\n",
        "    do_merge = do_merge.reset_index()\n",
        "#     do_merge = do_merge.set_index('조사일')\n",
        "#     print(do_merge)\n",
        "# do_merge = pd.merge(do_merge, z, left_on=do_merge.index, right_on=z.index)\n",
        "    \n",
        "# #     do_merge.columns = name\n",
        "    \n",
        "    return (do_merge, product)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akiBwIyu8TPz"
      },
      "source": [
        "def ForAllProduct(data, district):\n",
        "    test_market = data[(data['지역구']==district)&(data['구분']=='시장')]\n",
        "    test_outlet = data[(data['지역구']==district)&(data['구분']=='마트')]\n",
        "    seoul = data[(data['지역구']==district)]\n",
        "    test_list = test_market['품목'].unique()\n",
        "    print(test_list)\n",
        "\n",
        "    if len(test_list) == 5:\n",
        "        (test01, product1) = For_product(test_market, test_outlet, seoul, test_list[0])\n",
        "        (test02, product2) = For_product(test_market, test_outlet, seoul, test_list[1])\n",
        "        (test03, product3) = For_product(test_market, test_outlet, seoul, test_list[2])\n",
        "        (test04, product4) = For_product(test_market, test_outlet, seoul, test_list[3])\n",
        "        (test05, product5) = For_product(test_market, test_outlet, seoul, test_list[4])\n",
        "        (test06, product6) = (\"There is Only 5 products exist\", \"Nothing\")\n",
        "    elif len(test_list) == 6:\n",
        "        (test01, product1) = For_product(test_market, test_outlet, seoul, test_list[0])\n",
        "        (test02, product2) = For_product(test_market, test_outlet, seoul, test_list[1])\n",
        "        (test03, product3) = For_product(test_market, test_outlet, seoul, test_list[2])\n",
        "        (test04, product4) = For_product(test_market, test_outlet, seoul, test_list[3])\n",
        "        (test05, product5) = For_product(test_market, test_outlet, seoul, test_list[4])\n",
        "        (test06, product6) = For_product(test_market, test_outlet, seoul, test_list[5])\n",
        "        \n",
        "    return test01, test02, test03, test04, test05, test06"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw9GwVRS8ZQ_"
      },
      "source": [
        "금천구_배추, 금천구_무, 금천구_양파, 금천구_상추, 금천구_오이, test06= ForAllProduct(data, '금천구')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Rggrxs8Ghk"
      },
      "source": [
        "금천구_배추"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksRI2fUaEG9d"
      },
      "source": [
        "서울배추=금천구_배추[['조사일','서울']]\n",
        "서울배추.rename(columns={'조사일': '조사일', '서울': '서울배추'}, inplace=True)\n",
        "서울배추.set_index('조사일',inplace=True)\n",
        "\n",
        "서울무=금천구_무[['조사일','서울']]\n",
        "서울무.rename(columns={'조사일': '조사일', '서울': '서울무'}, inplace=True)\n",
        "서울무.set_index('조사일',inplace=True)\n",
        "\n",
        "서울양파=금천구_양파[['조사일','서울']]\n",
        "서울양파.rename(columns={'조사일': '조사일', '서울': '서울양파'}, inplace=True)\n",
        "서울양파.set_index('조사일',inplace=True)\n",
        "\n",
        "서울상추=금천구_상추[['조사일','서울']]\n",
        "서울상추.rename(columns={'조사일': '조사일', '서울': '서울상추'}, inplace=True)\n",
        "서울상추.set_index('조사일',inplace=True)\n",
        "\n",
        "서울오이=금천구_오이[['조사일','서울']]\n",
        "서울오이.rename(columns={'조사일': '조사일', '서울': '서울오이'}, inplace=True)\n",
        "서울오이.set_index('조사일',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbeFyspNEzci"
      },
      "source": [
        "서울평균채소가격=pd.concat([서울배추,서울무,서울양파,서울상추,서울오이],axis=1)\n",
        "서울평균채소가격.to_excel('서울평균채소가격.xlsx',index=False)\n",
        "서울평균채소가격.reset_index('조사일',inplace=True)\n",
        "서울평균채소가격.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X9UhbhZM2cE"
      },
      "source": [
        "서울품목별가격변동=pd.read_excel('/content/서울품별목별가격변동.xlsx')\n",
        "#서울품목별가격변동.to_excel('서울품목별가격변동.xlsx',index=False)\n",
        "#서울품목별가격변동.set_index('조사일',inplace=True)\n",
        "서울품목별가격변동.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNir6j0wM90c"
      },
      "source": [
        "# 양파 변동률 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBHkMZ2TPBFD"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "# loading dataset \n",
        "\n",
        "서울품목별가격변동=pd.read_excel(\"/content/서울품별목별가격변동.xlsx\")\n",
        "서울품목별가격변동.head()\n",
        "# draw lineplot \n",
        "plt.figsize=(50,50)\n",
        "sns.lineplot(x=\"조사일\", y=\"양파monthChange_rate\", data=서울품목별가격변동)\n",
        "plt.xlabel('날짜')\n",
        "plt.ylabel('양파가격변동률')\n",
        "plt.title('서울지역 양파 가격 변동률 그래프')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdqYiEPGNPPS"
      },
      "source": [
        "# 지도 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXMxGM6sKUNY"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr18Y0LcAjYK"
      },
      "source": [
        "###################### 지도 시각화\n",
        "import json\n",
        "with open('/content/서울경계데이터.json','r') as f:\n",
        "    json_data=json.load(f)\n",
        "print(json.dumps(json_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVcmGsSiK-nX"
      },
      "source": [
        "import folium\n",
        "m=folium.Map(location=[37.5838699,127.0565831],zoom_start=10)\n",
        "\n",
        "import json\n",
        "with open('/content/서울경계데이터.json','r') as f:\n",
        "    geo=json.loads(f.read())\n",
        "    f.close()\n",
        "\n",
        "folium.GeoJson(\n",
        "    geo,\n",
        "    name='seoul'\n",
        ").add_to(m)\n",
        "\n",
        "m.save('map.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d9MgGsjKW19"
      },
      "source": [
        "#html 코드 \n",
        "folium.Map().get_root().render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXnrebw1M90A"
      },
      "source": [
        "지도시각화_df=pd.read_excel('/content/지도 시각화_ 색깔별로 나눌거다 ㅡㅡ.xlsx')\n",
        "무지도시각화_df=지도시각화_df[지도시각화_df['품목']=='무']\n",
        "무지도시각화_df=무지도시각화_df[['구','가격']]\n",
        "무지도시각화_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wni0BWSKLLvW"
      },
      "source": [
        "# 서울시 중심부의 위도, 경도 입니다.\n",
        "center = [37.541, 126.986]\n",
        "\n",
        "# 맵이 center 에 위치하고, zoom 레벨은 11로 시작하는 맵 m을 만듭니다.\n",
        "m = folium.Map(location=center, zoom_start=10)\n",
        "\n",
        "# Choropleth 레이어를 만들고, 맵 m에 추가합니다.\n",
        "folium.Choropleth(\n",
        "    geo_data=geo,\n",
        "    data=무지도시각화_df,\n",
        "    columns=(\"구\",\"가격\"),\n",
        "    key_on='feature.properties.name',\n",
        "    fill_color='BuPu'\n",
        ").add_to(m)\n",
        "\n",
        "# 맵 m을 출력합니다.\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h4FIwX8Nh61"
      },
      "source": [
        "# 무 관련 한거임\n",
        "지도시각화_plz=pd.read_excel('/content/최종최종 최종 지도시각화 위도경도 있는 데이터다 ㅡㅡ.xlsx')\n",
        "지도시각화_plz=지도시각화_plz[지도시각화_plz['품목']=='무']\n",
        "지도시각화_plz=지도시각화_plz[['장소','평균 : 4년 평균 가격','위도','경도']]\n",
        "지도시각화_plz.columns=['장소','평균가격','위도','경도']\n",
        "지도시각화_plz.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AzY2cdKrLFE"
      },
      "source": [
        "import folium as g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CF9JULztYTe"
      },
      "source": [
        "for name,price,lat,lon in zip(지도시각화_plz.장소,지도시각화_plz.평균가격,지도시각화_plz.위도, 지도시각화_plz.경도):\n",
        "    g.Marker([lat, lon], \n",
        "             popup= name+str(price),\n",
        "             icon=g.Icon(color='red')).add_to(m)\n",
        "m0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUBgwlGKN025"
      },
      "source": [
        "# 가락시장데이터(경락가예측 전처리)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjYI9Qr8i4I"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import sys\n",
        "from openpyxl import load_workbook\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M31oQImgDB9Z"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfbH7lHO8zT2"
      },
      "source": [
        "배추_상_가격데이터=pd.read_excel('/content/배추(상, 10kg) 가락시장 가격 데이터.xlsx')\n",
        "배추_특_가격데이터=pd.read_excel('/content/배추(특, 10kg) 가락시장 가격 데이터.xlsx')\n",
        "배추_반입량=pd.read_excel('/content/복사본 배추 반입량(2017~20201031).xlsx')\n",
        "배추_강릉_기상=pd.read_excel('/content/복사본 배추_강릉_기상_20170101_20201031.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlFT5GzM-C35"
      },
      "source": [
        "배추_상_가격데이터['일자']= 배추_상_가격데이터['일자'].astype('str')\r\n",
        "배추_특_가격데이터['일자']= 배추_특_가격데이터['일자'].astype('str')\r\n",
        "배추_상_가격데이터['일자'] = pd.to_datetime(배추_상_가격데이터['일자'])\r\n",
        "배추_특_가격데이터['일자']= pd.to_datetime(배추_특_가격데이터['일자'])\r\n",
        "배추_반입량['거래일자']= 배추_반입량['거래일자'].astype('str')\r\n",
        "배추_반입량['거래일자'] = pd.to_datetime(배추_반입량['거래일자'])\r\n",
        "배추_반입량.rename(columns = {'거래일자' : '일자'}, inplace = True)\r\n",
        "배추_강릉_기상.rename(columns = {'일시' : '일자'}, inplace = True)\r\n",
        "배추_강릉_기상.head()\r\n",
        "배추_상_dt=pd.merge(pd.merge(배추_상_가격데이터,배추_반입량, on='일자'),배추_강릉_기상, on='일자')\r\n",
        "배추_상_dt.head()\r\n",
        "배추_특_dt=pd.merge(pd.merge(배추_특_가격데이터,배추_반입량,on='일자'),배추_강릉_기상,on='일자')\r\n",
        "배추_특_dt.head()\r\n",
        "배추_상_dt.to_excel('배추_상_dt.xlsx',index=False)\r\n",
        "배추_특_dt.to_excel('배추_특_dt.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX-tG58lOV4F"
      },
      "source": [
        "##########양파########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWdFTGNrPOZ3"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqC57G8PPREZ"
      },
      "source": [
        "양파_상_가격데이터=pd.read_excel('/content/양파 (상, 20kg) 가락시장 가격 데이터.xlsx')\n",
        "양파_특_가격데이터=pd.read_excel('/content/양파 (특, 20kg) 가락시장 가격 데이터.xlsx')\n",
        "양파_반입량=pd.read_excel('/content/복사본 양파 반입량(2017~20201031).xlsx')\n",
        "양파_해남_기상=pd.read_excel('/content/복사본 양파_해남_기상_20170101_20201031.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhjKiddeQYqJ"
      },
      "source": [
        "# 가격데이터 일자 컬럼 -> 날짜데이터로 변환\n",
        "양파_상_가격데이터['일자'] = 양파_상_가격데이터.astype(str)\n",
        "양파_상_가격데이터['일자'] = pd.to_datetime(양파_상_가격데이터['일자'],errors='coerce')\n",
        "양파_특_가격데이터['일자'] = 양파_특_가격데이터.일자.astype(str)\n",
        "양파_특_가격데이터['일자'] = pd.to_datetime(양파_특_가격데이터['일자'],errors='coerce')\n",
        "# 기상 데이터도 일자 변환해주기\n",
        "양파_해남_기상['일시'] = 양파_해남_기상.일시.astype(str)\n",
        "양파_해남_기상['일시'] = pd.to_datetime(양파_해남_기상['일시'],errors='coerce')\n",
        "# 반입량 데이터도 일자 변환해주기\n",
        "양파_반입량['거래일자'] = 양파_반입량.거래일자.astype(str)\n",
        "양파_반입량['거래일자'] = pd.to_datetime(양파_반입량['거래일자'],errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYW0mIDBU8Gi"
      },
      "source": [
        "양파_반입량.rename(columns={'거래일자' : '일자'}, inplace=True)\n",
        "양파_해남_기상.rename(columns={'일시' : '일자'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDiDEtp7R0Em"
      },
      "source": [
        "양파_상_dt = pd.merge(pd.merge(양파_상_가격데이터, 양파_해남_기상, on='일자', ),양파_반입량, on='일자')\n",
        "양파_상_dt.to_excel('양파_상_dt.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjH9ZnO-VNtS"
      },
      "source": [
        "양파_특_dt = pd.merge(pd.merge(양파_특_가격데이터, 양파_해남_기상, on='일자', ),양파_반입량, on='일자')\n",
        "양파_특_dt.to_excel('양파_특_dt.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5O4RxxmZnQx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import sys\n",
        "from openpyxl import load_workbook\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyLitT7kacjn"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTld2h7pr2dn"
      },
      "source": [
        "양파_특=pd.read_excel('/content/양파_특(20kg)_dt.xlsx')\n",
        "양파_상=pd.read_excel('/content/양파_상(20kg)_dt.xlsx')\n",
        "배추_특=pd.read_excel('/content/배추_특(10kg)_dt.xlsx')\n",
        "배추_상=pd.read_excel('/content/배추_상(10kg)_dt.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrStjAoQvHQM"
      },
      "source": [
        "del 양파_특['일자']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj2TwCwb__TA"
      },
      "source": [
        "양파_특=양파_특[['최저기온(°C)','최고기온(°C)','일강수량(mm)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','반입량']]\r\n",
        "양파_특corr = 양파_특.corr(method = 'pearson') \r\n",
        "#양파_특corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFAoaXVZA5_F"
      },
      "source": [
        "df_heatmap = sns.heatmap(양파_특corr, cbar = True, annot = True, annot_kws={'size' : 10}, fmt = '.2f', square = True, cmap = 'Blues')\n",
        "df_heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqyE0Mu7-E87"
      },
      "source": [
        "import scipy.stats as ss \n",
        "양파_특_ss=ss.zscore(양파_특)\n",
        "print(양파_특_ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrOB961LvhbO"
      },
      "source": [
        "pd.DataFrame(양파_특_ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CyBaEOMuveq"
      },
      "source": [
        "feature_columns=list(양파_특.columns.difference(['평균가격']))\n",
        "X=양파_특[feature_columns]\n",
        "y=양파_특.평균가격\n",
        "train_x,test_x,train_y,test_y=train_test_split(X,y,train_size=0.7,test_size=0.3)\n",
        "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWe1VkHUwUDj"
      },
      "source": [
        "#Train the MLR/회귀모델적합\n",
        "full_model=sm.OLS(train_y,train_x)\n",
        "fitted_full_model=full_model.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gljRPlJwlGE"
      },
      "source": [
        "fitted_full_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E9zuitVxcc7"
      },
      "source": [
        "# VIF를 통한 다중공선성 확인 \n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "vif=pd.DataFrame()\n",
        "vif['VIF Factor']=[variance_inflation_factor(양파_특.values,i) for i in range(양파_특.shape[1])]\n",
        "vif['features']=양파_특.columns\n",
        "vif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P9bqUhksx6A"
      },
      "source": [
        "# 변수선택법 \n",
        "def processSubset(X, y, feature_set):\n",
        "    model = sm.OLS(y, X[list(feature_set)]) # modeling\n",
        "    regr = model.fit() # 모델 학습\n",
        "    AIC = regr.aic # 모델의 AIC\n",
        "    return {'model' : regr, 'AIC' : AIC}\n",
        "\n",
        "print(processSubset(X=train_x, y = train_y, feature_set = feature_columns[0:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ4DOpCmtUgK"
      },
      "source": [
        "# 전진선택법(step=1)\n",
        "\n",
        "def forward(X, y, predictors):\n",
        "    # 데이터 변수들이 미리 정의된 predictors에 있는지 없는지 확인 및 분류\n",
        "    remaining_predictors = [p for p in X.columns.difference(['const']) if p not in predictors]\n",
        "    tic = time.time()\n",
        "    results = []\n",
        "    for p in remaining_predictors:\n",
        "        results.append(processSubset(X=X, y=y, feature_set=predcitors+[p]+['const']))\n",
        "    # 데이터프레임으로 변환\n",
        "    models = pd.DataFrame(results)\n",
        "    \n",
        "    # AIC가 가장 낮은 것을 선택\n",
        "    best_model = models.loc[models['AIC'].argmin()] # index\n",
        "    toc = time.time()\n",
        "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic))\n",
        "    print('Selected predictors:', best_model['model'].model.exog_names, ' AIC:',best_model[0])\n",
        "    return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPzqym-gyuIg"
      },
      "source": [
        "# 전진선택법 모델\n",
        "def forward_model(X,y):\n",
        "    Fmodels = pd.DataFrame(columns=['AID', 'model'])\n",
        "    tic = time.time()\n",
        "    # 미리 정의된 데이터 변수\n",
        "    predictors = []\n",
        "    # 변수 1~10개 : 0 ~ 9  -> 1 ~ 10\n",
        "    for i in range(1, len(X.columns.difference(['const'])) + 1):\n",
        "        Forward_result = forward(X=X, y=y, predictors=predictors)\n",
        "        if i > 1:\n",
        "            if Forward_result['AIC'] > Fmodel_before:\n",
        "                break\n",
        "        Fmodels.loc[i] = Forward_result\n",
        "        predictors = Fmodels.loc[i][\"model\"].model.exog_names\n",
        "        Fmodel_before = Fmodels.loc[i][\"AIC\"]\n",
        "        predictors = [ k for k in predictors if k != 'const']\n",
        "    toc = time.time()\n",
        "    print(\"Total elapsed time : \", (toc - tic), \"seconds.\")\n",
        "    \n",
        "    return (Fmodels['model'][len(Fmodels['model'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYTbpLExyyCw"
      },
      "source": [
        "#Forward_best_model = forward_model(X=train_x, y=train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvNb2UKyP6hc"
      },
      "source": [
        " # Prophet 시계열 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r8qhhd-2QQl"
      },
      "source": [
        "서울_전역=pd.read_excel('/content/서울_4년_평균.xlsx')\n",
        "서울_전역.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgbvX-e356eY"
      },
      "source": [
        "강남_양파_dt=서울_전역[(서울_전역['지역구']=='강남구')&(서울_전역['품목']=='양파')]\n",
        "강남_양파_dt=강남_양파_dt[['조사일','시장']]\n",
        "강남_양파_dt.set_index('조사일')\n",
        "강남_양파_dt.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sr9Mkmp8mW1"
      },
      "source": [
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sb8Me8o8z0S"
      },
      "source": [
        "강남_양파_dt.plot(x='조사일')\n",
        "plt.show()\n",
        "# 컬럼명 변경\n",
        "강남_양파_dt.columns = ['ds', 'y']\n",
        "\n",
        "# 데이터 타입 변경\n",
        "강남_양파_dt['ds']= pd.to_datetime(강남_양파_dt['ds'])\n",
        "\n",
        "# 모델 생성\n",
        "from fbprophet import Prophet\n",
        "model = Prophet()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(강남_양파_dt)\n",
        "\n",
        "# train set 마지막 1년 날짜 생성\n",
        "last_1year = list()\n",
        "for i in range(1,12):\n",
        "    last_1year.append(['2020-%01d' % i])\n",
        "last_1year = pd.DataFrame(last_1year, columns = ['ds'])\n",
        "last_1year['ds']= pd.to_datetime(last_1year['ds'])\n",
        "\n",
        "# 에측\n",
        "forecast = model.predict(last_1year)\n",
        "\n",
        "forecast.columns\n",
        "\n",
        "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head())\n",
        "model.plot(forecast)\n",
        "pyplot.show()\n",
        "\n",
        "# train set 이후 10개월 날짜 생성\n",
        "last_1year = list()\n",
        "for i in range(1, 10):\n",
        "    last_1year.append(['2020-%01d' % i])\n",
        "last_1year = pd.DataFrame(last_1year, columns = ['ds'])\n",
        "last_1year['ds']= pd.to_datetime(last_1year['ds'])\n",
        "\n",
        "forecast = model.predict(last_1year)\n",
        "model.plot(forecast)\n",
        "pyplot.show()\n",
        "\n",
        "# 마지막 12개월 제외시키기\n",
        "train = 강남_양파_dt.drop(강남_양파_dt.index[-9:])\n",
        "y_true = 강남_양파_dt['y'][-9:].values\n",
        "\n",
        "# 모델 생성 후 학습\n",
        "model = Prophet()\n",
        "model.fit(train)\n",
        "\n",
        "# train set 마지막 1년 날짜 생성\n",
        "last_1year = list()\n",
        "for i in range(1, 10):\n",
        "    last_1year.append(['2020-%01d' % i])\n",
        "last_1year = pd.DataFrame(last_1year, columns = ['ds'])\n",
        "last_1year['ds']= pd.to_datetime(last_1year['ds'])\n",
        "\n",
        "# 예측하고 비교하기\n",
        "# 여기에서는 MAE를 살펴본다.\n",
        "forecast = model.predict(last_1year)\n",
        "y_pred = forecast['yhat'].values\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "print('MAE: %.3f' % mae)\n",
        "\n",
        "pyplot.plot(y_true, label='Actual')\n",
        "pyplot.plot(y_pred, label='Predicted')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBqLWUReRY3o"
      },
      "source": [
        "# ARIMA 시계열 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2bXBrBjOP4F"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import sys\n",
        "from openpyxl import load_workbook\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qEUwG9Mm409"
      },
      "source": [
        "import warnings\n",
        "import itertools # 반복 가능한 데이터 스트림을 처리하는 데 유용한 많은 함수와 제네레이터가 포함\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use('fivethirtyeight')\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm #통계분석 기능을 제공하는 파이썬 패키지\n",
        "import matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bflSsbwQUkB"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJQv5MuCQWSo"
      },
      "source": [
        "서울_전역=pd.read_excel('/content/서울_4년_평균.xlsx')\n",
        "서울_전역.head()\n",
        "강남_양파_dt=서울_전역[(서울_전역['지역구']=='강남구')&(서울_전역['품목']=='양파')]\n",
        "강남_양파_dt.head()\n",
        "강남_양파_dt=강남_양파_dt[['조사일','시장']]\n",
        "강남_양파_dt.head()\n",
        "강남_양파_dt=강남_양파_dt.set_index('조사일')\n",
        "#강남_양파_dt=강남_양파_dt.iloc[0:46,0]\n",
        "#강남_양파_dt.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEfp-J7UREdV"
      },
      "source": [
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3CA67F2RIl5"
      },
      "source": [
        "강남_양파_dt.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IooD7PZ-RKzh"
      },
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.arima_model import ARIMAResults\n",
        "\n",
        "model=ARIMA(강남_양파_dt,order=(1,1,1))\n",
        "model_fit=model.fit(trend='c',full_output=True,disp=1)\n",
        "print(model_fit.summary())\n",
        "model_fit.plot_predict()\n",
        "p = d = q = range(0, 2)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
        "\n",
        "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
        "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))\n",
        "\n",
        "\n",
        "for param in pdq:\n",
        "    for param_seasonal in seasonal_pdq:\n",
        "        try:\n",
        "            mod = sm.tsa.statespace.SARIMAX(강남_양파_dt,\n",
        "                                            order=param,\n",
        "                                            seasonal_order=param_seasonal,\n",
        "                                            enforce_stationarity=False,\n",
        "                                            enforce_invertibility=False)\n",
        "            results = mod.fit()\n",
        "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
        "        except:\n",
        "            continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eO0yOaOnBpo"
      },
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.arima_model import ARIMAResults\n",
        "\n",
        "model=ARIMA(강남_양파_dt,order=(1,1,1), seasonal=(1,1,0,12))\n",
        "model_fit=model.fit(trend='nc',full_output=True,disp=1)\n",
        "print(model_fit.summary())\n",
        "model_fit.plot_predict()\n",
        "fore = model_fit.forecast(steps=1)\n",
        "print(fore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcBX8f0qVZyL"
      },
      "source": [
        "#경락가 다중회귀분석 & 변수선택법(1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gb5JIQoVZyY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import sys\n",
        "from openpyxl import load_workbook\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBJK_-0aVZyZ"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3KPeXLIVZya"
      },
      "source": [
        "양파_특=pd.read_excel('/content/양파_특(20kg)_dt.xlsx')\n",
        "양파_상=pd.read_excel('/content/양파_상(20kg)_dt.xlsx')\n",
        "배추_특=pd.read_excel('/content/배추_특(10kg)_dt.xlsx')\n",
        "배추_상=pd.read_excel('/content/배추_상(10kg)_dt.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5oALyX1VZya"
      },
      "source": [
        "del 양파_특['일자']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAO9mPcsVZya"
      },
      "source": [
        "양파_특=양파_특[['최저기온(°C)','최고기온(°C)','일강수량(mm)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','반입량']]\r\n",
        "양파_특corr = 양파_특.corr(method = 'pearson') \r\n",
        "#양파_특corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSlDIFNvVZyb"
      },
      "source": [
        "df_heatmap = sns.heatmap(양파_특corr, cbar = True, annot = True, annot_kws={'size' : 10}, fmt = '.2f', square = True, cmap = 'Blues')\n",
        "df_heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gScTr9FsVZyb"
      },
      "source": [
        "import scipy.stats as ss \n",
        "양파_특_ss=ss.zscore(양파_특)\n",
        "print(양파_특_ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZZUWIkVVZyb"
      },
      "source": [
        "pd.DataFrame(양파_특_ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFFsM1J8VZyb"
      },
      "source": [
        "feature_columns=list(양파_특.columns.difference(['평균가격']))\n",
        "X=양파_특[feature_columns]\n",
        "y=양파_특.평균가격\n",
        "train_x,test_x,train_y,test_y=train_test_split(X,y,train_size=0.7,test_size=0.3)\n",
        "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eH30lusVZyc"
      },
      "source": [
        "#Train the MLR/회귀모델적합\n",
        "full_model=sm.OLS(train_y,train_x)\n",
        "fitted_full_model=full_model.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc85p9cxVZyc"
      },
      "source": [
        "fitted_full_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_4LqLryVZyd"
      },
      "source": [
        "# VIF를 통한 다중공선성 확인 \n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "vif=pd.DataFrame()\n",
        "vif['VIF Factor']=[variance_inflation_factor(양파_특.values,i) for i in range(양파_특.shape[1])]\n",
        "vif['features']=양파_특.columns\n",
        "vif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb8G05YcVZyd"
      },
      "source": [
        "# 변수선택법 \n",
        "def processSubset(X, y, feature_set):\n",
        "    model = sm.OLS(y, X[list(feature_set)]) # modeling\n",
        "    regr = model.fit() # 모델 학습\n",
        "    AIC = regr.aic # 모델의 AIC\n",
        "    return {'model' : regr, 'AIC' : AIC}\n",
        "\n",
        "print(processSubset(X=train_x, y = train_y, feature_set = feature_columns[0:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76rJw26RVZyd"
      },
      "source": [
        "# 전진선택법(step=1)\n",
        "\n",
        "def forward(X, y, predictors):\n",
        "    # 데이터 변수들이 미리 정의된 predictors에 있는지 없는지 확인 및 분류\n",
        "    remaining_predictors = [p for p in X.columns.difference(['const']) if p not in predictors]\n",
        "    tic = time.time()\n",
        "    results = []\n",
        "    for p in remaining_predictors:\n",
        "        results.append(processSubset(X=X, y=y, feature_set=predcitors+[p]+['const']))\n",
        "    # 데이터프레임으로 변환\n",
        "    models = pd.DataFrame(results)\n",
        "    \n",
        "    # AIC가 가장 낮은 것을 선택\n",
        "    best_model = models.loc[models['AIC'].argmin()] # index\n",
        "    toc = time.time()\n",
        "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic))\n",
        "    print('Selected predictors:', best_model['model'].model.exog_names, ' AIC:',best_model[0])\n",
        "    return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q4R9p_5VZyd"
      },
      "source": [
        "# 전진선택법 모델\n",
        "def forward_model(X,y):\n",
        "    Fmodels = pd.DataFrame(columns=['AID', 'model'])\n",
        "    tic = time.time()\n",
        "    # 미리 정의된 데이터 변수\n",
        "    predictors = []\n",
        "    # 변수 1~10개 : 0 ~ 9  -> 1 ~ 10\n",
        "    for i in range(1, len(X.columns.difference(['const'])) + 1):\n",
        "        Forward_result = forward(X=X, y=y, predictors=predictors)\n",
        "        if i > 1:\n",
        "            if Forward_result['AIC'] > Fmodel_before:\n",
        "                break\n",
        "        Fmodels.loc[i] = Forward_result\n",
        "        predictors = Fmodels.loc[i][\"model\"].model.exog_names\n",
        "        Fmodel_before = Fmodels.loc[i][\"AIC\"]\n",
        "        predictors = [ k for k in predictors if k != 'const']\n",
        "    toc = time.time()\n",
        "    print(\"Total elapsed time : \", (toc - tic), \"seconds.\")\n",
        "    \n",
        "    return (Fmodels['model'][len(Fmodels['model'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94RaLMM9VZye"
      },
      "source": [
        "#Forward_best_model = forward_model(X=train_x, y=train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R1NDzYTU7TZ"
      },
      "source": [
        "# 경락가 다중회귀분석 & 변수선택법(2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZaxL3HSh2eD"
      },
      "source": [
        "양파_dt=양파_dt[['최저기온(°C)','최고기온(°C)','일강수량(mm)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','반입량','평균가격','유가 전국평균가격']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7-f4ph2kNh4"
      },
      "source": [
        "양파_dt.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU1oHTavchv1"
      },
      "source": [
        "# 설명변수(X),타겟변수(Y) 분리 및 학습 데이터와 평가 데이터 분할\n",
        "feature_columns=list(양파_dt.columns.difference(['평균가격']))\n",
        "X=양파_dt[feature_columns]\n",
        "y=양파_dt.평균가격\n",
        "train_x,test_x,train_y,test_y=train_test_split(X,y,train_size=0.7,test_size=0.3)\n",
        "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjQikuIfijQw"
      },
      "source": [
        "#Train the MLR/회귀모델적합\n",
        "full_model=sm.OLS(train_y,train_x)\n",
        "fitted_full_model=full_model.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyWjGYFZjKs5"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "vif=pd.DataFrame()\n",
        "vif['VIF Factor']=[variance_inflation_factor(양파_dt.values,i) for i in range(양파_dt.shape[1])]\n",
        "vif['features']=양파_dt.columns\n",
        "vif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nA1a-YCkDnc"
      },
      "source": [
        "양파_dt=양파_dt[['최저기온(°C)','최고기온(°C)','일강수량(mm)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','반입량','평균가격','유가 전국평균가격']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj1O3dSXoK4u"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "vif=pd.DataFrame()\n",
        "vif['VIF Factor']=[variance_inflation_factor(양파_dt.values,i) for i in range(양파_dt.shape[1])]\n",
        "vif['features']=양파_dt.columns\n",
        "vif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLVduBlVoNzy"
      },
      "source": [
        "양파_dt=양파_dt[['최저기온(°C)','일강수량(mm)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','반입량','평균가격','유가 전국평균가격']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub5IoQDsoUio"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "vif=pd.DataFrame()\n",
        "vif['VIF Factor']=[variance_inflation_factor(양파_dt.values,i) for i in range(양파_dt.shape[1])]\n",
        "vif['features']=양파_dt.columns\n",
        "vif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4M-nOOioVjs"
      },
      "source": [
        "양파_dt=양파_dt[['최저기온(°C)','일강수량(mm)','평균 풍속(m/s)','합계 일조시간(hr)','반입량','유가 전국평균가격']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r97KZ1t7ofeY"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "vif=pd.DataFrame()\n",
        "vif['VIF Factor']=[variance_inflation_factor(양파_dt.values,i) for i in range(양파_dt.shape[1])]\n",
        "vif['features']=양파_dt.columns\n",
        "vif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCGMGQsXog43"
      },
      "source": [
        "# 변수선택법 \n",
        "def processSubset(X, y, feature_set):\n",
        "    model = sm.OLS(y, X[list(feature_set)]) # modeling\n",
        "    regr = model.fit() # 모델 학습\n",
        "    AIC = regr.aic # 모델의 AIC\n",
        "    return {'model' : regr, 'AIC' : AIC}\n",
        "\n",
        "print(processSubset(X=train_x, y = train_y, feature_set = feature_columns[0:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq0LAfXm411y"
      },
      "source": [
        "# 전진선택법(step=1)\n",
        "\n",
        "def forward(X, y, predictors):\n",
        "    # 데이터 변수들이 미리 정의된 predictors에 있는지 없는지 확인 및 분류\n",
        "    remaining_predictors = [p for p in X.columns.difference(['평균가격']) if p not in predictors]\n",
        "    tic = time.time()\n",
        "    results = []\n",
        "    for p in remaining_predictors:\n",
        "        results.append(processSubset(X=X, y=y, feature_set=predcitors+[p]+['평균가격']))\n",
        "    # 데이터프레임으로 변환\n",
        "    models = pd.DataFrame(results)\n",
        "    \n",
        "    # AIC가 가장 낮은 것을 선택\n",
        "    best_model = models.loc[models['AIC'].argmin()] # index\n",
        "    toc = time.time()\n",
        "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic))\n",
        "    print('Selected predictors:', best_model['model'].model.exog_names, ' AIC:',best_model[0])\n",
        "    return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmVUj0X247mU"
      },
      "source": [
        "# 전진선택법 모델\n",
        "def forward_model(X,y):\n",
        "    Fmodels = pd.DataFrame(columns=['AID', 'model'])\n",
        "    tic = time.time()\n",
        "    # 미리 정의된 데이터 변수\n",
        "    predictors = []\n",
        "    # 변수 1~10개 : 0 ~ 9  -> 1 ~ 10\n",
        "    for i in range(1, len(X.columns.difference(['평균가격'])) + 1):\n",
        "        Forward_result = forward(X=X, y=y, predictors=predictors)\n",
        "        if i > 1:\n",
        "            if Forward_result['AIC'] > Fmodel_before:\n",
        "                break\n",
        "        Fmodels.loc[i] = Forward_result\n",
        "        predictors = Fmodels.loc[i][\"model\"].model.exog_names\n",
        "        Fmodel_before = Fmodels.loc[i][\"AIC\"]\n",
        "        predictors = [ k for k in predictors if k != '평균가격']\n",
        "    toc = time.time()\n",
        "    print(\"Total elapsed time : \", (toc - tic), \"seconds.\")\n",
        "    \n",
        "    return (Fmodels['model'][len(Fmodels['model'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGLKLugO5Ko6"
      },
      "source": [
        "#Forward_best_model = forward_model(X=train_x, y=train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhfuOI505NN3"
      },
      "source": [
        "양파_dt=양파_dt[['최저기온(°C)','일강수량(mm)','평균 풍속(m/s)','합계 일조시간(hr)','반입량','유가 전국평균가격','평균가격']]\n",
        "양파_dt.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iItBlRHf9E3t"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "X_data=양파_dt[['최저기온(°C)','일강수량(mm)','평균 풍속(m/s)','합계 일조시간(hr)','반입량','유가 전국평균가격']]\n",
        "Y_data=양파_dt[['평균가격']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daqGLsG8-N9U"
      },
      "source": [
        "#다중선형회귀모델 설계\n",
        "linear_regression_model=linear_model.LinearRegression()\n",
        "linear_regression_model.fit(X_data,Y_data)\n",
        "linear_regression_model_prediction=linear_regression_model.predict(X=pd.DataFrame(X_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUo26Fpq_pM-"
      },
      "source": [
        "#Train the MLR / 회귀모델적합\n",
        "fullModel = sm.OLS(train_y,train_x)\n",
        "fittedFullModel = fullModel.fit()\n",
        " \n",
        "#R-Squre 가 높고 , 대부분의 변수들이 유의함.\n",
        "print(fittedFullModel.summary())\n",
        " \n",
        "#VIF를 통한 다중공선성 확인\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        " \n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF Factor\"] = [variance_inflation_factor(양파_dt.values,i)\n",
        "                     for i in range(양파_dt.shape[1])]\n",
        "vif[\"features\"]=양파_dt.columns\n",
        "print(vif)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYLoltMiBRGg"
      },
      "source": [
        "#학습데이터의 잔차 확인\n",
        " \n",
        "res = fittedFullModel.resid\n",
        "import matplotlib.pyplot as plt\n",
        "#Q-Q plot # 정규분포확인\n",
        "fig = sm.qqplot(res, fit=True, line='45')\n",
        "plt.show()\n",
        "# residual pattern 확인\n",
        " \n",
        "predY = fittedFullModel.predict(train_x)\n",
        " \n",
        "fig = plt.scatter(predY,res,s=4)\n",
        "plt.xlim(4000,30000)\n",
        "plt.xlim(4000,30000)\n",
        "plt.xlabel('Fitted values')\n",
        "plt.ylabel('Residual')\n",
        "plt.show()\n",
        " \n",
        "#검증 데이터에 대한 예측\n",
        " \n",
        "predY2 = fittedFullModel.predict(test_x)\n",
        " \n",
        "plt.plot(np.array(test_y-predY2),label=\"predFull\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        " \n",
        "#MSE 값 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "MSE = mean_squared_error(y_true=test_y,y_pred=predY2)\n",
        "print(MSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSSry3frCRHg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EceUNvh8VvJL"
      },
      "source": [
        "# 데이터 시각화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flIsk1NVWJD0"
      },
      "source": [
        "####요일별 평균 가격비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThrwTohU3oQf"
      },
      "source": [
        "pip install sklearn pandas matplotlib graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSslMtzw3rHO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl9VcKRS9Ot0"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhA0aNgk6nHx"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdEc6Ke-6pTF"
      },
      "source": [
        "무_상=pd.read_excel('/content/무_상.xlsx')\n",
        "무_특=pd.read_excel('/content/무_특.xlsx')\n",
        "#무_상.head()\n",
        "무_상.info()  # 14개의 컬럼과 2090개의 index를 가지고 있음\n",
        "무_특.info() # 14개의 컬럼과 2090개의 index를 가지고 있음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VRq7Dst79EW"
      },
      "source": [
        "무_상_요일별평균가격=무_상[['평균가격','요일(1)']]\n",
        "무_상_요일별평균가격.head()\n",
        "무_상_요일별평균가격.groupby(무_상_요일별평균가격['요일(1)']).mean('평균가격')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xQ_z1Hc73wU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFuQDs-C8Wzp"
      },
      "source": [
        "# Basic Bar Chart\n",
        "plt.plot()\n",
        "sns.barplot(x='요일(1)',y='평균가격',data=무_상_요일별평균가격)\n",
        "plt.title('무_상_요일 별 평균가격')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBvS57mi8jgC"
      },
      "source": [
        "무_특_요일별평균가격=무_특[['평균가격','요일(1)']]\n",
        "무_특_요일별평균가격.head()\n",
        "무_특_요일별평균가격.groupby(무_특_요일별평균가격['요일(1)']).mean('평균가격'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvoYn-_L9mpr"
      },
      "source": [
        "plt.plot()\n",
        "sns.barplot(x='요일(1)',y='평균가격',data=무_특_요일별평균가격)\n",
        "plt.title('무_특_요일 별 평균가격')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZCNNJh9WuUm"
      },
      "source": [
        "#### 가격 분포 히스토그램"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLHWYm5U-nbr"
      },
      "source": [
        "무_상.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCo_ZyJy9zxe"
      },
      "source": [
        "plt.hist(무_상['평균가격'], range=(2000,40000))\n",
        "plt.title('무상 평균가격대 분포 히스토그램')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex9FDTFa_Mtg"
      },
      "source": [
        "무_특.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRwF2cM1-EU_"
      },
      "source": [
        "plt.hist(무_특['평균가격'], range=(4000,45000))\n",
        "plt.title('무_특 평균가격대 분포 히스토그램')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5UfhptpXpPC"
      },
      "source": [
        "#### 날씨 상관관계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qrk5Ecd_bXr"
      },
      "source": [
        "무_상_기상상관관계=무_상[['최저기온(°C)','최고기온(°C)','일강수량(mm)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','일교차']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GmdP4rQ_nlx"
      },
      "source": [
        "#heatmap으로 상관관계를 표시\n",
        "import seaborn as sb\n",
        "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "sb.heatmap(무_상_기상상관관계.corr(),\n",
        "           annot = True, #실제 값 화면에 나타내기\n",
        "           cmap = 'Greens', #색상\n",
        "           vmin = -1, vmax=1 , #컬러차트 영역 -1 ~ +1\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUjCQoZ8fXEI"
      },
      "source": [
        "무_특_기상상관관계=무_특[['최저기온(°C)','최고기온(°C)','일강수량(mm)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','일교차']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP6QjL3mfaRC"
      },
      "source": [
        "sns.pairplot(무_특_기상상관관계)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpOKXNE7GG5W"
      },
      "source": [
        "### 반입량 평균가격 산점도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQpaZO-rF_mq"
      },
      "source": [
        "# 무_상 평균가격 반입량 산점도\n",
        "# Basic Scatter Plot\n",
        "\n",
        "plt.plot('평균가격',  # x \n",
        "         '반입량',  # y\n",
        "         data=무_상, \n",
        "         linestyle='none', \n",
        "         marker='o', \n",
        "         markersize=2,\n",
        "         color='blue', \n",
        "         alpha=0.5)\n",
        "plt.title('무_상 평균가격_반입량 산점도')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Nzv8VyiIbs"
      },
      "source": [
        "# 무_특 평균가격 반입량 산점도\n",
        "# Basic Scatter Plot\n",
        "\n",
        "plt.plot('평균가격',  # x \n",
        "         '반입량',  # y\n",
        "         data=무_특, \n",
        "         linestyle='none', \n",
        "         marker='o', \n",
        "         markersize=2,\n",
        "         color='blue', \n",
        "         alpha=0.5)\n",
        "plt.title('무_특 평균가격_반입량 산점도')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEKhRnl1aNiF"
      },
      "source": [
        "### 월별평균가격과 반입량 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLHP9M-2KsIZ"
      },
      "source": [
        "무_상.set_index('일자',inplace=True)\r\n",
        "무상_평균가격= 무_상[['평균가격','반입량']].resample('MS').mean()\r\n",
        "무상_평균가격\r\n",
        "무_특.set_index('일자',inplace=True)\r\n",
        "무_특_평균가격= 무_특[['평균가격','반입량']].resample('MS').mean()\r\n",
        "무_특_평균가격"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQOmAv_bZXUK"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "a=np.linspace(0,5,200)\r\n",
        "\r\n",
        "ax=무_특_평균가격.plot(kind='line', x='일자', y='평균가격', color='DarkBlue')\r\n",
        "\r\n",
        "ax2=무_특_평균가격.plot(kind='line', x='일자', y='반입량', secondary_y=True, color='Red', ax=ax)\r\n",
        "\r\n",
        "ax.set_ylabel('반입량')\r\n",
        "ax2.set_ylabel('평균가격')\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whnJLP28ZcuR"
      },
      "source": [
        "plt.plot(무_특_평균가격['평균가격'], color='green', linestyle='-',label='평균가격')\r\n",
        "plt.plot(무_특_평균가격['반입량'], color='blue',  linestyle='-',label='반입량')\r\n",
        "plt.legend()\r\n",
        "plt.title('무_특 2013~2020 월별 평균가격과 반입량 추세 그래프 ')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YmfV7BmbVz7"
      },
      "source": [
        "# 경락가 예측 XGBRegressor(1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlADbia0bV0L"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VLdomzHbV0N"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nopQ51PXbV0O"
      },
      "source": [
        "양파_반입량=pd.read_excel('/content/양파 반입량 통합2013-2020.xlsx')\n",
        "양파_경락가=pd.read_excel('/content/양파(특) 경락가 통합2013-2020.xlsx')\n",
        "양파_해남_기상=pd.read_excel('/content/양파_해남20130101_20201031.xlsx')\n",
        "주유소_판매가격=pd.read_excel('/content/주유소_평균판매가격.xlsx')\n",
        "양파_반입량.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20IrdMvMbV0P"
      },
      "source": [
        "양파_경락가.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBdzmrFVbV0Q"
      },
      "source": [
        "양파_경락_반입=pd.merge(양파_반입량,양파_경락가,on='일자')\n",
        "양파_경락_반입.head()\n",
        "양파_경락_반입['일자'] = 양파_경락_반입['일자'].astype(str)\n",
        "양파_경락_반입['일자'] = pd.to_datetime(양파_경락_반입['일자'])\n",
        "양파_경락_반입.info()\n",
        "#양파_해남_기상.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylDz5XrQbV0Q"
      },
      "source": [
        "양파_해남_기상.rename(columns = {'일시': '일자'}, inplace = True)\r\n",
        "양파_dt=pd.merge(양파_해남_기상,양파_경락_반입,on='일자')\r\n",
        "양파_dt=pd.merge(양파_dt,주유소_판매가격,on='일자')\r\n",
        "양파_dt[['일교차']]=양파_dt['최고기온(°C)']-양파_dt['최저기온(°C)']\r\n",
        "양파_dt=양파_dt[['최저기온(°C)','최고기온(°C)','일강수량(mm)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','반입량','유가 전국평균가격','일교차','평균가격']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKa1D3k-bV0R"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fr7r54dbV0R"
      },
      "source": [
        "X, y = 양파_dt.iloc[:,:-1],양파_dt.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6_d88YdbV0S"
      },
      "source": [
        "data_dmatrix = xgb.DMatrix(data=X,label=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3Ws8wOgbV0S"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7fNyjAfbV0Y"
      },
      "source": [
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)\r\n",
        "xg_reg.fit(X_train,y_train)\r\n",
        "preds = xg_reg.predict(X_test)\r\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\r\n",
        "print(\"RMSE: %f\" % (rmse))\r\n",
        "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,'max_depth': 5, 'alpha': 10}\r\n",
        "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\r\n",
        "cv_results.head()\r\n",
        "print((cv_results[\"test-rmse-mean\"]).tail(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA2ayPFTbV0Z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "xgb.plot_tree(xg_reg,num_trees=0)\n",
        "plt.rcParams['figure.figsize'] = [40, 10]\n",
        "plt.show()\n",
        "print((cv_results[\"test-rmse-mean\"]).tail(1))\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "\n",
        "# 변수중요도\n",
        "xgb.plot_importance(xg_reg)\n",
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnP9PHtObhJ0"
      },
      "source": [
        "# 경락가 예측 XGBRegressor(2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2cOTUL8E1Yr"
      },
      "source": [
        "pip install sklearn pandas matplotlib graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0FSGLZ_FA15"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLaZ73CPFA62"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCgRRTmdFA9w"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OXP4XG2FA_3"
      },
      "source": [
        "서울_양파_가격=pd.read_excel('/content/서울전역시장마트데이터(구분포함,23월포함).xlsx')\n",
        "양파_특_가락시장_data=pd.read_excel('/content/양파_특.xlsx')\n",
        "서울날씨=pd.read_excel('/content/seoul_weather.xlsx')\n",
        "공휴일=pd.read_excel('/content/holiday.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYPUksAa9O4K"
      },
      "source": [
        "서울_양파_가격.head()\r\n",
        "서울날씨.rename(columns = {'일시':'일자'}, inplace = True)\r\n",
        "서울날씨.head()\r\n",
        "공휴일.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWtzwuyXMrmf"
      },
      "source": [
        "서울_양파_가격=서울_양파_가격[(서울_양파_가격['품목']=='양파')&(서울_양파_가격['구분']=='마트')]\r\n",
        "서울_양파_가격=서울_양파_가격.groupby('조사일').mean()\r\n",
        "서울_양파_가격.reset_index('조사일',inplace = True)\r\n",
        "서울_양파_가격.rename(columns = {'조사일':'일자'}, inplace = True)\r\n",
        "양파_특_가락시장_data.rename(columns = {'평균가격':'경락가평균가격'}, inplace = True)\r\n",
        "양파_통합 =pd.merge(서울_양파_가격, 양파_특_가락시장_data, on='일자')\r\n",
        "양파_통합=pd.merge(양파_통합,공휴일,on='일자')\r\n",
        "양파_통합=pd.merge(양파_통합,서울날씨,on='일자')\r\n",
        "양파_통합.to_excel('양파_마트통합.xlsx')\r\n",
        "양파_통합=양파_통합[['가격','반입량','경락가평균가격','유가 전국평균가격','유무','최저기온(°C)','최고기온(°C)','일강수량(mm)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs41OCVkFBCa"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_importance \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAbY3c5dFBHK"
      },
      "source": [
        "양파_통합.data=양파_통합[['반입량','경락가평균가격','유가 전국평균가격','최저기온(°C)','최고기온(°C)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 5cm 지중온도(°C)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNY8IijRD1t2"
      },
      "source": [
        "#양파_통합.data=양파_통합[['반입량','경락가평균가격','유가 전국평균가격','평균 풍속(m/s)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn1IfA3TFBMD"
      },
      "source": [
        "양파_통합.target=양파_통합[['가격']]\r\n",
        "x,y=양파_통합.data,양파_통합.target\r\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDNQJTI3FBKS"
      },
      "source": [
        "xgbr = xgb.XGBRegressor(verbosity=0) \n",
        "print(xgbr)\n",
        "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
        "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
        "       n_jobs=1, nthread=None, objective='reg', random_state=0,\n",
        "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "       silent=None, subsample=1, verbosity=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVE4pJ4CFXaR"
      },
      "source": [
        "xgbr.fit(xtrain, ytrain)\r\n",
        "score = xgbr.score(xtrain, ytrain)  \r\n",
        "print(\"Training score: \", score)\r\n",
        "scores = cross_val_score(xgbr, xtrain, ytrain,cv=10)\r\n",
        "print(\"Mean cross-validation score: %.2f\" % scores.mean())\r\n",
        "kfold = KFold(n_splits=10, shuffle=True)\r\n",
        "kf_cv_scores = cross_val_score(xgbr, xtrain, ytrain, cv=kfold )\r\n",
        "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\r\n",
        "ypred = xgbr.predict(xtest)\r\n",
        "mse = mean_squared_error(ytest, ypred)\r\n",
        "print(\"MSE: %.2f\" % mse)\r\n",
        "print(\"RMSE: %.2f\" % (mse**(1/2.0)))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyQ3GKWEc7H3"
      },
      "source": [
        "x_ax = range(len(ytest))\r\n",
        "plt.plot(x_ax, ytest, label=\"original\")\r\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\r\n",
        "plt.title(\" test and predicted data\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj6HS58SdH6r"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plot_importance(xgbr)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXqcUXyMEAdY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV76HHX5eVXQ"
      },
      "source": [
        "# 경락가 예측 XGBRegressor(3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9walbHdiQbm_"
      },
      "source": [
        "pip install sklearn pandas matplotlib graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAM2IdvRQce6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLPeDFEpQkl_"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMJ9387UiTa4"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyBGLrC9QoJj"
      },
      "source": [
        "서울_무_가격=pd.read_excel('/content/서울전역시장마트데이터(구분포함,23월포함).xlsx')\n",
        "무_특_가락시장_data=pd.read_excel('/content/무_특.xlsx')\n",
        "서울날씨=pd.read_excel('/content/seoul_weather.xlsx')\n",
        "공휴일=pd.read_excel('/content/holiday.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6-hduzSq7s4"
      },
      "source": [
        "무_도매=pd.read_excel('/content/서울 평균 도매가격(무).xlsx')\r\n",
        "무_도매['서울평균도매가격']=무_도매['서울평균도매가격']/20\r\n",
        "무_도매=무_도매[['일자','서울평균도매가격']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgjDF4I1Q6Qr"
      },
      "source": [
        "서울날씨.rename(columns = {'일시':'일자'}, inplace = True)\n",
        "서울날씨.head()\n",
        "#공휴일.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83NDRcIlQ-TN"
      },
      "source": [
        "서울_무_가격=서울_무_가격[(서울_무_가격['품목']=='무')&(서울_무_가격['구분']=='시장')]\r\n",
        "서울_무_가격=서울_무_가격.groupby('조사일').mean()\r\n",
        "서울_무_가격.reset_index('조사일',inplace = True)\r\n",
        "서울_무_가격.rename(columns = {'조사일':'일자'}, inplace = True)\r\n",
        "서울_무_가격.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN8WfTU7RL1G"
      },
      "source": [
        "무_특_가락시장_data.rename(columns = {'평균가격':'경락가평균가격'}, inplace = True)\n",
        "무_특_가락시장_data=무_특_가락시장_data[['일자','경락가평균가격','반입량','유가 전국평균가격','일교차']]\n",
        "무_특_가락시장_data['경락가평균가격']=무_특_가락시장_data['경락가평균가격']/20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzekIpeRRL51"
      },
      "source": [
        "무_통합 =pd.merge(서울_무_가격, 무_특_가락시장_data, on='일자')\r\n",
        "무_통합=pd.merge(무_통합,공휴일,on='일자')\r\n",
        "무_통합=pd.merge(무_통합,서울날씨,on='일자')\r\n",
        "무_통합=pd.merge(무_통합,무_도매,on='일자')\r\n",
        "무_통합.to_excel('무_시장.xlsx')\r\n",
        "무_통합.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MxzkOOcQpJj"
      },
      "source": [
        "최저시급=pd.read_excel('/content/최저시급.xlsx')\r\n",
        "# 가격데이터 일자 컬럼 -> 날짜데이터로 변환\r\n",
        "최저시급['일자'] = 최저시급.일자.astype(str)\r\n",
        "최저시급['일자'] = pd.to_datetime(최저시급['일자'])\r\n",
        "무_통합=pd.merge(무_통합, 최저시급,  on='일자')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnnT_Uw-RR7n"
      },
      "source": [
        "무_통합=무_통합[['최저시급','가격','반입량','경락가평균가격','유가 전국평균가격','서울평균도매가격','유무','최저기온(°C)','최고기온(°C)','일강수량(mm)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5346cnn-RR96"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_importance \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASo9cMnyRScJ"
      },
      "source": [
        "무_통합.data=무_통합[['반입량','경락가평균가격','유가 전국평균가격','서울평균도매가격','최저시급']]\n",
        "#,'일강수량(mm)','최저기온(°C)','최고기온(°C)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)',"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "984kloBXRShV"
      },
      "source": [
        "무_통합.target=무_통합[['가격']]\r\n",
        "x,y=무_통합.data,무_통합.target\r\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)\r\n",
        "xgbr = xgb.XGBRegressor(verbosity=0) \r\n",
        "print(xgbr)\r\n",
        "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\r\n",
        "       colsample_bynode=1, colsample_bytree=1, gamma=0,\r\n",
        "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\r\n",
        "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\r\n",
        "       n_jobs=1, nthread=None, objective='reg', random_state=0,\r\n",
        "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\r\n",
        "       silent=None, subsample=1, verbosity=1)\r\n",
        "xgbr.fit(xtrain, ytrain)\r\n",
        "score = xgbr.score(xtrain, ytrain)  \r\n",
        "print(\"Training score: \", score)\r\n",
        "scores = cross_val_score(xgbr, xtrain, ytrain,cv=10)\r\n",
        "print(\"Mean cross-validation score: %.2f\" % scores.mean())\r\n",
        "kfold = KFold(n_splits=10, shuffle=True)\r\n",
        "kf_cv_scores = cross_val_score(xgbr, xtrain, ytrain, cv=kfold )\r\n",
        "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\r\n",
        "ypred = xgbr.predict(xtest)\r\n",
        "mse = mean_squared_error(ytest, ypred)\r\n",
        "print(\"MSE: %.2f\" % mse)\r\n",
        "print(\"RMSE: %.2f\" % (mse**(1/2.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SjEnnKRSJ8T"
      },
      "source": [
        "x_ax = range(len(ytest))\r\n",
        "plt.plot(x_ax, ytest, label=\"original\")\r\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\r\n",
        "plt.title(\" test and predicted data\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlPSi3YVbV0b"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plot_importance(xgbr)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXdmJ5EEgval"
      },
      "source": [
        "# 소비자가격 예측 머신러닝(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d04a0Ltvh1oQ"
      },
      "source": [
        "#### 오이(시장) 소비자가 전처리 및 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGJ2HcW388b6"
      },
      "source": [
        "pip install sklearn pandas matplotlib graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K99G6509Elk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SroORl029G1-"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHgy-Nj99Jx5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znfWuDxBToRe"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX2KK-569t3a"
      },
      "source": [
        "오이_도매가격=pd.read_excel('/content/서울 평균 도매가격(오이).xlsx')\n",
        "오이_시장마트가격=pd.read_excel('/content/서울전역시장마트데이터(구분포함,23월포함).xlsx')\n",
        "오이_경락가=pd.read_excel('/content/오이_경락가.xlsx')\n",
        "오이_반입량=pd.read_excel('/content/오이_반입량.xlsx')\n",
        "유가가격=pd.read_excel('/content/주유소_평균판매가격.xlsx')\n",
        "서울날씨=pd.read_excel('/content/seoul_weather.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XyluC8s-haB"
      },
      "source": [
        "오이_도매가격=오이_도매가격[['date','wholesale_price(1pc)']]\r\n",
        "오이_도매가격.rename(columns={'date':'일자'},inplace=True)\r\n",
        "오이_시장가격=오이_시장마트가격[(오이_시장마트가격['품목']=='오이')&(오이_시장마트가격['구분']=='시장')]\r\n",
        "오이_시장가격=오이_시장가격[['조사일','가격']]\r\n",
        "오이_시장가격=오이_시장가격.groupby('조사일').mean()\r\n",
        "오이_시장가격.reset_index('조사일',inplace=True)\r\n",
        "오이_시장가격.rename(columns={'조사일':'일자'},inplace=True)\r\n",
        "오이_시장가격.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNJFmdJJAble"
      },
      "source": [
        "오이_경락가.head()\r\n",
        "오이_경락가['일자'] = 오이_경락가.일자.astype(str)\r\n",
        "오이_경락가['일자'] = pd.to_datetime(오이_경락가['일자'])\r\n",
        "오이_경락가.rename(columns={'오이 1개 평균가격':'오이1개 경락가'},inplace=True)\r\n",
        "오이_경락가=오이_경락가[['일자','평균가격(1)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpuK-C5HA3_U"
      },
      "source": [
        "오이_반입량.head()\r\n",
        "오이_반입량.rename(columns={'거래일자':'일자'},inplace=True)\r\n",
        "오이_반입량['일자'] = pd.to_datetime(오이_반입량['일자'])\r\n",
        "오이_반입량=오이_반입량[['일자','반입량']]\r\n",
        "#오이_반입량.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5n_hNMPBdra"
      },
      "source": [
        "#유가가격.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZWpk62lBkMq"
      },
      "source": [
        "서울날씨.rename(columns={'일시':'일자'},inplace=True)\r\n",
        "오이_시장=pd.merge(오이_시장가격,오이_도매가격,on='일자')\r\n",
        "오이_시장=pd.merge(오이_시장,오이_경락가,on='일자')\r\n",
        "오이_시장=pd.merge(오이_반입량,오이_시장,on='일자')\r\n",
        "오이_시장=pd.merge(유가가격,오이_시장,on='일자')\r\n",
        "오이_시장=pd.merge(오이_시장,서울날씨,on='일자')\r\n",
        "오이_시장.to_excel('오이_시장.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3CsIfnIEnPY"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_importance \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqn-FPjXZIQW"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYgUnNp7ZQO0"
      },
      "source": [
        "오이_시장=pd.read_excel('/content/오이_시장.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nIaHgMLFOYk"
      },
      "source": [
        "x_data=오이_시장[['유가 전국평균가격','반입량','wholesale_price(1pc)','평균가격(1)','최저기온(°C)','최고기온(°C)','일강수량(mm)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)']]\n",
        "y_target=오이_시장[['가격']]\n",
        "x,y=x_data,y_target\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)\n",
        "# 변수 다있었을 때\n",
        "# x_data=오이_시장[['유가 전국평균가격','반입량','wholesale_price(1pc)','평균가격(1)','최저기온(°C)','최고기온(°C)','일강수량(mm)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)']]\n",
        "# 0.83\n",
        "# 날씨 변수 제외하면?\n",
        "#x_data=오이_시장[['유가 전국평균가격','반입량','wholesale_price(1pc)','오이1개 경락가']]\n",
        "# 0.77"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nbztuhfFrsN"
      },
      "source": [
        "xgbr = xgb.XGBRegressor(verbosity=0) \n",
        "xgbr.fit(xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG1Qp_ehFtOh"
      },
      "source": [
        "score = xgbr.score(xtrain, ytrain)  \n",
        "print(\"Training score: \", score)\n",
        "scores = cross_val_score(xgbr, xtrain, ytrain)\n",
        "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
        "#kfold = KFold(n_splits=8, shuffle=True)\n",
        "#kf_cv_scores = cross_val_score(xgbr, xtrain, ytrain, cv=kfold )\n",
        "#print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
        "ypred = xgbr.predict(xtest)\n",
        "mse = mean_squared_error(ytest, ypred)\n",
        "print(\"MSE: %.2f\" % mse)\n",
        "print(\"RMSE: %.2f\" % (mse**(1/2.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA_wuSpbFvDZ"
      },
      "source": [
        "x_ax = range(len(ytest))\n",
        "plt.plot(x_ax, ytest, label=\"original\")\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\n",
        "plt.title(\" test and predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5r4Fe1hFxWk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_importance(xgbr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O-S8C_8F8Vb"
      },
      "source": [
        "rf=RandomForestRegressor(random_state=0,n_estimators=1000)\n",
        "neg_mse_scores=cross_val_score(rf,x_data,y_target,scoring='neg_mean_squared_error',cv=5)\n",
        "rmse_scores=np.sqrt(-1*neg_mse_scores)\n",
        "avg_rmse=np.mean(rmse_scores)\n",
        "\n",
        "print('5교차의 개별 Negative MSE scores : ',np.round(neg_mse_scores,2))\n",
        "print('5교차 검증의 개별 RMSE score : ',np.round(rmse_scores,2))\n",
        "print('5교차 검증의 평균 RMSE : {0:3f}'.format(avg_rmse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b38XESz8HawK"
      },
      "source": [
        "def get_model_cv_prediction(model, x_data,y_target):\n",
        "    neg_mse_scores=cross_val_score(model,x_data,y_target,scoring='neg_mean_squared_error',cv=5)\n",
        "    rmse_scores=np.sqrt(-1*neg_mse_scores)\n",
        "    avg_rmse=np.mean(rmse_scores)\n",
        "    print('####',model.__class__.__name__,'####')\n",
        "    print('5교차 검증의 평균 RMSE : {0:3f}'.format(avg_rmse))\n",
        "    score = xgbr.score(xtrain, ytrain)  \n",
        "    print(\"Training score: \", score)\n",
        "    scores = cross_val_score(xgbr, xtrain, ytrain,cv=10)\n",
        "    print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
        "    kfold = KFold(n_splits=10, shuffle=True)\n",
        "    kf_cv_scores = cross_val_score(xgbr, xtrain, ytrain, cv=kfold )\n",
        "    print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNo8S9idHgcc"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "dt_reg=DecisionTreeRegressor(random_state=0,max_depth=4)\n",
        "rf_reg=RandomForestRegressor(random_state=0,n_estimators=1000)\n",
        "gb_reg=GradientBoostingRegressor(random_state=0,n_estimators=1000)\n",
        "xgb_reg=XGBRegressor(n_estimators=1000)\n",
        "lgb_reg=LGBMRegressor(n_estimators=1000)\n",
        "\n",
        "# 트리기반의 회귀 모델을 반복하면서 평가 수행\n",
        "models=[dt_reg,rf_reg,gb_reg,xgb_reg,lgb_reg]\n",
        "for model in models:\n",
        "    get_model_cv_prediction(model, x_data, y_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukp5xjLMHib6"
      },
      "source": [
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "rf_reg=RandomForestRegressor(n_estimators=1000)\n",
        "\n",
        "rf_reg.fit(x_data, y_target)\n",
        "\n",
        "feature_series=pd.Series(data=rf_reg.feature_importances_,index=x_data.columns)\n",
        "feature_series=feature_series.sort_values(ascending=False)\n",
        "sns.barplot(x=feature_series,y=feature_series.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1cqFkgcHxZu"
      },
      "source": [
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "xgb_reg=XGBRegressor(n_estimators=1000)\n",
        "\n",
        "xgb_reg.fit(x_data, y_target)\n",
        "\n",
        "feature_series=pd.Series(data=xgb_reg.feature_importances_,index=x_data.columns)\n",
        "feature_series=feature_series.sort_values(ascending=False)\n",
        "sns.barplot(x=feature_series,y=feature_series.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSdJJNMGIokh"
      },
      "source": [
        "#### 오이(마트) 소비자가 전처리 및 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K617suHmIoDN"
      },
      "source": [
        "오이_마트가격=오이_시장마트가격[(오이_시장마트가격['품목']=='오이')&(오이_시장마트가격['구분']=='마트')]\r\n",
        "오이_마트가격=오이_마트가격[['조사일','가격']]\r\n",
        "오이_마트가격=오이_마트가격.groupby('조사일').mean()\r\n",
        "오이_마트가격.reset_index('조사일',inplace=True)\r\n",
        "오이_마트가격.rename(columns={'조사일':'일자'},inplace=True)\r\n",
        "오이_마트=pd.merge(오이_마트가격,오이_도매가격,on='일자')\r\n",
        "오이_마트=pd.merge(오이_마트,오이_경락가,on='일자')\r\n",
        "오이_마트=pd.merge(오이_반입량,오이_마트,on='일자')\r\n",
        "오이_마트=pd.merge(유가가격,오이_마트,on='일자')\r\n",
        "오이_마트=pd.merge(오이_마트,서울날씨,on='일자')\r\n",
        "오이_마트.to_excel('오이_마트.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh-sYJOgKcw8"
      },
      "source": [
        "x_data=오이_마트[['유가 전국평균가격','반입량','wholesale_price(1pc)','평균가격(1)','최저기온(°C)','최고기온(°C)','일강수량(mm)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)']]\n",
        "y_target=오이_마트[['가격']]\n",
        "x,y=x_data,y_target\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)\n",
        "xgbr = xgb.XGBRegressor(verbosity=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuvJnFpYkF6k"
      },
      "source": [
        "xgbr.fit(xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbh3Mu0QkOQT"
      },
      "source": [
        "score = xgbr.score(xtrain, ytrain)  \n",
        "print(\"Training score: \", score)\n",
        "scores = cross_val_score(xgbr, xtrain, ytrain,cv=10)\n",
        "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "kf_cv_scores = cross_val_score(xgbr, xtrain, ytrain, cv=kfold )\n",
        "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
        "ypred = xgbr.predict(xtest)\n",
        "mse = mean_squared_error(ytest, ypred)\n",
        "print(\"MSE: %.2f\" % mse)\n",
        "print(\"RMSE: %.2f\" % (mse**(1/2.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7WCybiakPy3"
      },
      "source": [
        "x_ax = range(len(ytest))\n",
        "plt.plot(x_ax, ytest, label=\"original\")\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\n",
        "plt.title(\" test and predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzCw08tYjxwI"
      },
      "source": [
        "#### 상추(시장) 소비자가 전처리 및 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHYEK879rXun"
      },
      "source": [
        "pip install sklearn pandas matplotlib graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blh6GYWRrdg0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSI_zHiZricW"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axH3XNQBrkX2"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ji1uxIr5Bs"
      },
      "source": [
        "상추_시장=pd.read_excel('/content/상추_시장_통합본.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfU34jiormPk"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_importance \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQUF8EtesH7Y"
      },
      "source": [
        "상추_시장.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1heYpNwXrxj2"
      },
      "source": [
        "x_data=상추_시장[['반입량','100g가격','최저기온(°C)','최고기온(°C)','일강수량(mm)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)','여부','유가 전국평균가격',\t'도매가격']]\n",
        "y_target=상추_시장[['가격']]\n",
        "x,y=x_data,y_target\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdB7Rmzrtnjq"
      },
      "source": [
        "xgbr = xgb.XGBRegressor(verbosity=0) \r\n",
        "xgbr.fit(xtrain, ytrain)\r\n",
        "score = xgbr.score(xtrain, ytrain)  \r\n",
        "print(\"Training score: \", score)\r\n",
        "scores = cross_val_score(xgbr, xtrain, ytrain,cv=10)\r\n",
        "print(\"Mean cross-validation score: %.2f\" % scores.mean())\r\n",
        "kfold = KFold(n_splits=10, shuffle=True)\r\n",
        "kf_cv_scores = cross_val_score(xgbr, xtrain, ytrain, cv=kfold )\r\n",
        "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\r\n",
        "ypred = xgbr.predict(xtest)\r\n",
        "mse = mean_squared_error(ytest, ypred)\r\n",
        "print(\"MSE: %.2f\" % mse)\r\n",
        "print(\"RMSE: %.2f\" % (mse**(1/2.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-hm20E-tyu1"
      },
      "source": [
        "x_ax = range(len(ytest))\n",
        "plt.plot(x_ax, ytest, label=\"original\")\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\n",
        "plt.title(\" test and predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNJ3rmPft5OQ"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uCdPYNHkaRx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icuw1nazkr8Y"
      },
      "source": [
        "# 소비자가격 예측 머신러닝(2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeHIkP-KUPoz"
      },
      "source": [
        "pip install sklearn pandas matplotlib graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSmuMUSWUV6E"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import itertools\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXAhMFjcUV9h"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REPxJICpiHyC"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqUqv2r-UWHU"
      },
      "source": [
        "무_시장=pd.read_excel('/content/무_시장.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYAUW9ePUWJm"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_importance \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B586hkiWP2MX"
      },
      "source": [
        "무_시장.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyLYoh1QUcFy"
      },
      "source": [
        "x_data=무_시장[['경락가평균가격','반입량','유가 전국평균가격','유무','최저기온(°C)','최고기온(°C)','일강수량(mm)','도매가격']]\n",
        "y_target=무_시장[['가격']]\n",
        "x,y=x_data,y_target\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GxxiWELT3Ks"
      },
      "source": [
        "from scipy import stats\n",
        "from scipy.stats import norm\n",
        "import seaborn as sns\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD_EGSF4UCiN"
      },
      "source": [
        "sns.distplot(y_target, rug=True)\r\n",
        "y_target=np.log1p(y_target)\r\n",
        "y_target.hist()\r\n",
        "무_시장['가격']=np.log1p(무_시장['가격'])\r\n",
        "sns.distplot(무_시장['가격'],fit=norm)\r\n",
        "stats.probplot(무_시장['가격'], plot=plt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxcHbzAbWhdr"
      },
      "source": [
        "##### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GolMU0QXw-uw"
      },
      "source": [
        "무_시장=무_시장.drop(['Unnamed: 0','일자', '일교차','유무' ,'최저기온(°C)','최고기온(°C)','일강수량(mm)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYrQgJSsxHD2"
      },
      "source": [
        "x_data=무_시장[['반입량','경락가평균가격','유가 전국평균가격','서울평균도매가격']]\n",
        "y_target=무_시장[['가격']]\n",
        "x,y=x_data,y_target\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg6u8UEmzHLT"
      },
      "source": [
        "sns.distplot(무_시장['가격'],fit=norm)\r\n",
        "stats.probplot(무_시장['가격'],plot=plt)\r\n",
        "무_시장['가격']=np.log1p(무_시장['가격'])\r\n",
        "sns.distplot(무_시장['가격'],fit=norm)\r\n",
        "stats.probplot(무_시장['가격'], plot=plt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmhk1i3xUcIT"
      },
      "source": [
        "xgbr = xgb.XGBRegressor(verbosity=0) \n",
        "print(xgbr)\n",
        "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
        "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
        "       n_jobs=1, nthread=None, objective='reg', random_state=100,\n",
        "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "       silent=None, subsample=1, verbosity=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR-BWNBkUcKr"
      },
      "source": [
        "xgbr.fit(xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz5I0j_iUWLy"
      },
      "source": [
        "score = xgbr.score(xtrain, ytrain)  \n",
        "print(\"Training score: \", score)\n",
        "scores = cross_val_score(xgbr, xtrain, ytrain,cv=10)\n",
        "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
        "ypred = xgbr.predict(xtest)\n",
        "mse = mean_squared_error(ytest, ypred)\n",
        "print(\"MSE: %.2f\" % mse)\n",
        "print(\"RMSE: %.2f\" % (mse**(1/2.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIApAoWM3SYp"
      },
      "source": [
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzt2uz0MUsK9"
      },
      "source": [
        "x_ax = range(len(ytest))\n",
        "plt.plot(x_ax, ytest, label=\"original\")\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\n",
        "plt.title(\" test and predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5adiB4BnUsP1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_importance(xgbr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTkBdTMNWwr2"
      },
      "source": [
        "#####RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErNnDfuRUsON"
      },
      "source": [
        "rf=RandomForestRegressor(random_state=0,n_estimators=1000)\n",
        "neg_mse_scores=cross_val_score(rf,x_data,y_target,scoring='neg_mean_squared_error')\n",
        "rmse_scores=np.sqrt(-1*neg_mse_scores)\n",
        "avg_rmse=np.mean(rmse_scores)\n",
        "\n",
        "print('5교차의 개별 Negative MSE scores : ',np.round(neg_mse_scores,2))\n",
        "print('5교차 검증의 개별 RMSE score : ',np.round(rmse_scores,2))\n",
        "print('5교차 검증의 평균 RMSE : {0:3f}'.format(avg_rmse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i_s0GtJYnAl"
      },
      "source": [
        "def get_model_cv_prediction(model, x_data,y_target):\n",
        "    neg_mse_scores=cross_val_score(model,x_data,y_target,scoring='neg_mean_squared_error',cv=5)\n",
        "    rmse_scores=np.sqrt(-1*neg_mse_scores)\n",
        "    avg_rmse=np.mean(rmse_scores)\n",
        "    print('####',model.__class__.__name__,'####')\n",
        "    print('5교차 검증의 평균 RMSE : {0:3f}'.format(avg_rmse))\n",
        "    score = xgbr.score(xtrain, ytrain)  \n",
        "    print(\"Training score: \", score)\n",
        "    scores = cross_val_score(xgbr, xtrain, ytrain,cv=10)\n",
        "    print(\"Mean cross-validation score: %.2f\" % scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7sF1z8yZS31"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "dt_reg=DecisionTreeRegressor(random_state=0,max_depth=4)\n",
        "rf_reg=RandomForestRegressor(random_state=0,n_estimators=1000)\n",
        "gb_reg=GradientBoostingRegressor(random_state=0,n_estimators=1000)\n",
        "xgb_reg=XGBRegressor(n_estimators=1000)\n",
        "lgb_reg=LGBMRegressor(n_estimators=1000)\n",
        "\n",
        "# 트리기반의 회귀 모델을 반복하면서 평가 수행\n",
        "models=[dt_reg,rf_reg,gb_reg,xgb_reg,lgb_reg]\n",
        "for model in models:\n",
        "    get_model_cv_prediction(model, x_data, y_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUV0i0ZqagpV"
      },
      "source": [
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "rf_reg=RandomForestRegressor(n_estimators=1000)\n",
        "\n",
        "rf_reg.fit(x_data, y_target)\n",
        "\n",
        "feature_series=pd.Series(data=rf_reg.feature_importances_,index=x_data.columns)\n",
        "feature_series=feature_series.sort_values(ascending=False)\n",
        "sns.barplot(x=feature_series,y=feature_series.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_C1RRYNlEW7"
      },
      "source": [
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "xgb_reg=XGBRegressor(n_estimators=1000)\n",
        "\n",
        "xgb_reg.fit(x_data, y_target)\n",
        "\n",
        "feature_series=pd.Series(data=xgb_reg.feature_importances_,index=x_data.columns)\n",
        "feature_series=feature_series.sort_values(ascending=False)\n",
        "sns.barplot(x=feature_series,y=feature_series.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESUouwUMf233"
      },
      "source": [
        "x_ax = range(len(ytest))\n",
        "plt.plot(x_ax, ytest, label=\"original\")\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\n",
        "plt.title(\" test and predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njiuL92wmF3y"
      },
      "source": [
        "### BaggingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0wNK3ucmHaZ"
      },
      "source": [
        "무_시장.head()\r\n",
        "data=무_시장.drop(['Unnamed: 0','일자', '일교차','유무' ,'최저기온(°C)','최고기온(°C)','일강수량(mm)','최대 풍속(m/s)','평균 풍속(m/s)','평균 상대습도(%)','합계 일조시간(hr)','평균 지면온도(°C)','평균 5cm 지중온도(°C)'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPFed2YOsmar"
      },
      "source": [
        "data['가격']=np.log1p(data['가격'])\n",
        "sns.distplot(data['가격'],fit=norm)\n",
        "stats.probplot(data['가격'], plot=plt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK35c-vomniX"
      },
      "source": [
        "feature_columns=list(data.columns.difference(['가격']))\n",
        "X=data[feature_columns]\n",
        "y=data['가격']\n",
        "train_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.15,random_state=42)\n",
        "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiDcHVoqnbl3"
      },
      "source": [
        "# 학습데이터를 선형 회귀 모형에 적합 후 평가 데이터로 검증"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9plxzI61rUpH"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from math import sqrt, log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6e0UQeoprZi"
      },
      "source": [
        "regression_model=LinearRegression()\n",
        "linear_model1=regression_model.fit(train_x,train_y)\n",
        "predict1=linear_model1.predict(test_x)\n",
        "print('RMSE:{}'.format(sqrt(mean_squared_error(predict1,test_y))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqGBzyDwok-L"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "bagging_model=BaggingRegressor(base_estimator=regression_model,\n",
        "                               n_estimators=10,\n",
        "                               verbose=1)\n",
        "linear_model2=bagging_model.fit(train_x,train_y)\n",
        "predict2=linear_model2.predict(test_x)\n",
        "print('RMSE:{}'.format(sqrt(mean_squared_error(predict2,test_y))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTXLxjRmsRCr"
      },
      "source": [
        "bagging_mode2=BaggingRegressor(base_estimator=regression_model,\n",
        "                               n_estimators=30,\n",
        "                               verbose=1)\n",
        "linear_model3=bagging_mode2.fit(train_x,train_y)\n",
        "predict3=linear_model3.predict(test_x)\n",
        "print('RMSE:{}'.format(sqrt(mean_squared_error(predict3,test_y))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zWNSPVSsdFC"
      },
      "source": [
        "# DecisionTreeRegressor\n",
        "# BaggingRegressor에서  base_estimator를 decision_tree_model로 변경 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5EbNHyFtuI3"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "decision_tree_model=DecisionTreeRegressor()\n",
        "tree_model1=decision_tree_model.fit(train_x,train_y)\n",
        "predict1=tree_model1.predict(test_x)\n",
        "print('RMSE:{}'.format(sqrt(mean_squared_error(predict1,test_y))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdewDiH0uSPZ"
      },
      "source": [
        "bagging_decision_model1=BaggingRegressor(base_estimator=decision_tree_model,\n",
        "                               n_estimators=10,\n",
        "                               verbose=1)\n",
        "tree_model2=bagging_decision_model1.fit(train_x,train_y)\n",
        "predict2=tree_model2.predict(test_x)\n",
        "print('RMSE:{}'.format(sqrt(mean_squared_error(predict2,test_y))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ViOHTqulcH"
      },
      "source": [
        "bagging_decision_model1=BaggingRegressor(base_estimator=decision_tree_model,\n",
        "                               n_estimators=30,\n",
        "                               verbose=1)\n",
        "tree_model2=bagging_decision_model1.fit(train_x,train_y)\n",
        "predict2=tree_model2.predict(test_x)\n",
        "print('RMSE:{}'.format(sqrt(mean_squared_error(predict2,test_y))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJk4SrQYxKIF"
      },
      "source": [
        "### 예측 모델링\r\n",
        "\r\n",
        "* DecisionTreeRegressor\r\n",
        "* RandomForestRegressor\r\n",
        "* GradientBoostingRegressor\r\n",
        "* XGBRegressor\r\n",
        "* LGBMRegressor\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC2sZIc4xKIU"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "dt_reg=DecisionTreeRegressor(random_state=0,max_depth=4)\n",
        "rf_reg=RandomForestRegressor(random_state=0,n_estimators=1000)\n",
        "gb_reg=GradientBoostingRegressor(random_state=0,n_estimators=1000)\n",
        "xgb_reg=XGBRegressor(n_estimators=1000)\n",
        "lgb_reg=LGBMRegressor(n_estimators=1000)\n",
        "\n",
        "# 트리기반의 회귀 모델을 반복하면서 평가 수행\n",
        "models=[dt_reg,rf_reg,gb_reg,xgb_reg,lgb_reg]\n",
        "for model in models:\n",
        "    get_model_cv_prediction(model, x_data, y_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoyREpiBxKIa"
      },
      "source": [
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "rf_reg=RandomForestRegressor(n_estimators=1000)\n",
        "\n",
        "rf_reg.fit(x_data, y_target)\n",
        "\n",
        "feature_series=pd.Series(data=rf_reg.feature_importances_,index=x_data.columns)\n",
        "feature_series=feature_series.sort_values(ascending=False)\n",
        "sns.barplot(x=feature_series,y=feature_series.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3_muxSRxKIb"
      },
      "source": [
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "xgb_reg=XGBRegressor(n_estimators=1000)\n",
        "\n",
        "xgb_reg.fit(x_data, y_target)\n",
        "\n",
        "feature_series=pd.Series(data=xgb_reg.feature_importances_,index=x_data.columns)\n",
        "feature_series=feature_series.sort_values(ascending=False)\n",
        "sns.barplot(x=feature_series,y=feature_series.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwB1epUzxKIc"
      },
      "source": [
        "x_ax = range(len(ytest))\n",
        "plt.plot(x_ax, ytest, label=\"original\")\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\n",
        "plt.title(\" test and predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN7haEhVnw0H"
      },
      "source": [
        "# 최종모델 선정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwOGoDQan5Zn"
      },
      "source": [
        "## hyper_Parameter(무_시장)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9EEJGCOus4W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k8DZfe7mEan"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ght0hmsAgAED"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD6UE9D7dphU"
      },
      "source": [
        "# 코랩 한글깨짐 설정\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n",
        " \r\n",
        "%config InlineBackend.figure_format = 'retina'\r\n",
        " \r\n",
        "!apt -qq -y install fonts-nanum\r\n",
        " \r\n",
        "import matplotlib.font_manager as fm\r\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\r\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\r\n",
        "plt.rc('font', family='NanumBarunGothic') \r\n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kppA_WKAr_Tm"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V3Mgndss9iT"
      },
      "source": [
        "dataset = pd.read_excel('/content/무_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDaJN4u5Irq1"
      },
      "source": [
        "dataset['가격']= np.log1p(dataset['가격'])\r\n",
        "dataset['경락가평균가격']= np.log1p(dataset['경락가평균가격'])\r\n",
        "dataset['반입량']= np.log1p(dataset['반입량'])\r\n",
        "dataset['유가 전국평균가격']= np.log1p(dataset['유가 전국평균가격'])\r\n",
        "dataset['도매가격']= np.log1p(dataset['도매가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cixhfSxnKw49"
      },
      "source": [
        "dataset1=dataset[['가격','경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "dataset1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GxasvMmLahM"
      },
      "source": [
        "dataset2=dataset[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxk-cc1WVFFq"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "dataset2[:]=scalar.fit_transform(dataset2[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4c67xCLPN6T"
      },
      "source": [
        "dataset2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB9bv9HsPRcn"
      },
      "source": [
        "dataset=pd.concat([dataset1,dataset2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxwijxorPmUr"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCvv_BRjtGan"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyeZE--HtHWl"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh77Y8bXtNQW"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 3)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql8ToBz_gP3i"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2k6b5aRozW1"
      },
      "source": [
        "##### ParameterTuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S11ES3a40jX"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S0k-S5B40sa"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN4Gz1kf40y9"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0yX6PRhq8Vg"
      },
      "source": [
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTFOYkPFuH-n"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.7, \n",
        "                       gamma = 0.1,\n",
        "                       learning_rate = 0.03,\n",
        "                       max_depth = 3,\n",
        "                       min_child_weight = 5,\n",
        "                       n_estimators = 200,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.7)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 7,\n",
        "                               max_features = 3,\n",
        "                               min_samples_leaf = 3,\n",
        "                               min_samples_split = 8,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.7,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.1,\n",
        "                        max_depth = 7,\n",
        "                        min_child_samples = 20,\n",
        "                        n_estimators = 100,\n",
        "                        num_leaves =8,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.1,\n",
        "                                   max_depth=7,\n",
        "                                   n_estimators=100,\n",
        "                                   subsample=0.7\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2GAHHKpuIA-"
      },
      "source": [
        "#ypred = rf_reg.predict(X_test)\n",
        "#mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTja4A6yuIDD"
      },
      "source": [
        "#x_ax = range(len(y_test))\n",
        "#plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "#plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "#plt.title(\"Price Prediction\")\n",
        "#plt.legend()\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLwaHJIyuIE9"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\r\n",
        "\r\n",
        "er = VotingRegressor([('xgb_reg', xgb_reg), ('gb_reg', gb_reg),('lgb_reg',lgb_reg)])\r\n",
        "print(er.fit(X_train, y_train).predict(X_test))\r\n",
        "y_pred = er.fit(X_train, y_train).predict(X_test)\r\n",
        "er.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaxrslxBuRcV"
      },
      "source": [
        "x_ax = range(len(y_test))\r\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\r\n",
        "plt.plot(x_ax, y_pred, label=\"Predicted Price\")\r\n",
        "plt.title(\"Price Prediction\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtpJ8UqyuRej"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\r\n",
        "from sklearn.linear_model import RidgeCV\r\n",
        "from sklearn.svm import LinearSVR\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.ensemble import StackingRegressor\r\n",
        "y_target = dataset['가격']\r\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\r\n",
        "estimators= ([('xgb_reg', xgb_reg), ('rf_reg', rf_reg), ('lgb_reg', lgb_reg), ('gb_reg', gb_reg)])\r\n",
        "reg = StackingRegressor(estimators=estimators,final_estimator=RandomForestRegressor(n_estimators=10,random_state=42))\r\n",
        "reg.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XEjwhntpTo4"
      },
      "source": [
        "##### 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3nI9wbZA6hv"
      },
      "source": [
        "##########예측"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm_l948QAu06"
      },
      "source": [
        "무_더미= pd.read_excel('/content/무_더미(예측).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al7S6HQOAvA7"
      },
      "source": [
        "#무_더미['가격']= np.log1p(무_더미['가격'])\r\n",
        "무_더미['경락가평균가격']= np.log1p(무_더미['경락가평균가격'])\r\n",
        "무_더미['반입량']= np.log1p(무_더미['반입량'])\r\n",
        "무_더미['유가 전국평균가격']= np.log1p(무_더미['유가 전국평균가격'])\r\n",
        "무_더미['도매가격']= np.log1p(무_더미['도매가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hV5fgWYAvKU"
      },
      "source": [
        "무_더미1=무_더미[['경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "무_더미1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0k3jZ5zBX12"
      },
      "source": [
        "무_더미2=무_더미[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTP1QB-sBX2C"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "무_더미2[:]=scalar.fit_transform(무_더미2[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTFv1SxrBX2C"
      },
      "source": [
        "무_더미2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEj-h_ZbBX2D"
      },
      "source": [
        "무_더미=pd.concat([무_더미1,무_더미2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klCNf-j9AEU3"
      },
      "source": [
        "ypred = er.predict(무_더미)\r\n",
        "ypred\r\n",
        "#mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIY5S02MAZyX"
      },
      "source": [
        "무_더미['예측가격'] = ypred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuD8GVzrF8VA"
      },
      "source": [
        "무_더미['예측가격']=np.expm1(무_더미['예측가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL_OYS_sL-W1"
      },
      "source": [
        "무_더미.to_excel('무_더미(예측완료).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoHFPrh6qJwj"
      },
      "source": [
        "## hyper_Parameter(배추_시장)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6CbR0M4p7m9"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRMerWmjp7m-"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLOP6QfHp7m_"
      },
      "source": [
        "dataset = pd.read_excel('/content/배추_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw4AABkdK8qO"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUPXjw6kCtbF"
      },
      "source": [
        "###예측##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfu7rgpyBPHY"
      },
      "source": [
        "dataset['가격']= np.log1p(dataset['가격'])\r\n",
        "dataset['경락가평균가격']= np.log1p(dataset['경락가평균가격'])\r\n",
        "dataset['반입량']= np.log1p(dataset['반입량'])\r\n",
        "dataset['유가 전국평균가격']= np.log1p(dataset['유가 전국평균가격'])\r\n",
        "dataset['도매가격']= np.log1p(dataset['도매가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJKQebJEBPHZ"
      },
      "source": [
        "dataset1=dataset[['가격','경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "dataset1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js_PKIwxBPHZ"
      },
      "source": [
        "dataset2=dataset[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2nIQF3kBPHZ"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "dataset2[:]=scalar.fit_transform(dataset2[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5T12ayrBPHa"
      },
      "source": [
        "dataset2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDPCOZpwBPHa"
      },
      "source": [
        "dataset=pd.concat([dataset1,dataset2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ktCCf5gBPHa"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzFLMHo_p7nC"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taEAt5Uep7nD"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k43J4wKKp7nD"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 3)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL_NSVNjp7nE"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8ZRSHHfqmbC"
      },
      "source": [
        "#### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FylPsBjyp7nJ"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jFIMS_wp7nM"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NPORmmjp7nM"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ra-KOXrp7nN"
      },
      "source": [
        "\n",
        "#rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "#rf_parameter\n",
        "\n",
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O-Thlm_p7nN"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.7, \n",
        "                       gamma = 0.2,\n",
        "                       learning_rate = 0.1,\n",
        "                       max_depth = 5,\n",
        "                       min_child_weight = 1,\n",
        "                       n_estimators = 500,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.7)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 10,\n",
        "                               max_features = 3,\n",
        "                               min_samples_leaf = 3,\n",
        "                               min_samples_split = 8,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.7,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.03,\n",
        "                        max_depth = 7,\n",
        "                        min_child_samples = 10,\n",
        "                        n_estimators = 200,\n",
        "                        num_leaves =8,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.1,\n",
        "                                   max_depth=3,\n",
        "                                   n_estimators=200,\n",
        "                                   subsample=0.5\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76ButkZNp7nP"
      },
      "source": [
        "ypred = rf_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir4EBfbVp7nP"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcMTxzgBp7nQ"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\r\n",
        "\r\n",
        "er = VotingRegressor([('xgb_reg', xgb_reg), ('gb_reg', gb_reg),('lgb_reg',lgb_reg),('rf_reg',rf_reg)])\r\n",
        "print(er.fit(X_train, y_train).predict(X_test))\r\n",
        "y_pred = er.fit(X_train, y_train).predict(X_test)\r\n",
        "er.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC1Hfrs4p7nU"
      },
      "source": [
        "x_ax = range(len(y_test))\r\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\r\n",
        "plt.plot(x_ax, y_pred, label=\"Predicted Price\")\r\n",
        "plt.title(\"Price Prediction\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NVT7uGvp7nV"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\r\n",
        "from sklearn.linear_model import RidgeCV\r\n",
        "from sklearn.svm import LinearSVR\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.ensemble import StackingRegressor\r\n",
        "y_target = dataset['가격']\r\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\r\n",
        "estimators= ([('xgb_reg', xgb_reg), ('rf_reg', rf_reg), ('lgb_reg', lgb_reg), ('gb_reg', gb_reg)])\r\n",
        "reg = StackingRegressor(estimators=estimators,final_estimator=RandomForestRegressor(n_estimators=10,random_state=42))\r\n",
        "reg.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVdAyENgqzkO"
      },
      "source": [
        "#### 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JsOgN1DBbqV"
      },
      "source": [
        "배추_더미= pd.read_excel('/content/배추_더미(예측).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJjimnCNBbqY"
      },
      "source": [
        "#무_더미['가격']= np.log1p(무_더미['가격'])\r\n",
        "배추_더미['경락가평균가격']= np.log1p(배추_더미['경락가평균가격'])\r\n",
        "배추_더미['반입량']= np.log1p(배추_더미['반입량'])\r\n",
        "배추_더미['유가 전국평균가격']= np.log1p(배추_더미['유가 전국평균가격'])\r\n",
        "배추_더미['도매가격']= np.log1p(배추_더미['도매가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSTa8InuBbqa"
      },
      "source": [
        "배추_더미1=배추_더미[['경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "배추_더미1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOBUq-R-Bbqb"
      },
      "source": [
        "배추_더미2=배추_더미[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0lTQrtoBbqd"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "배추_더미2[:]=scalar.fit_transform(배추_더미2[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJYk8DsgBbqf"
      },
      "source": [
        "배추_더미2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8tkoZgwBbqg"
      },
      "source": [
        "배추_더미=pd.concat([배추_더미1,배추_더미2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWfckXy4Bbqj"
      },
      "source": [
        "ypred = gb_reg.predict(배추_더미)\r\n",
        "ypred\r\n",
        "#mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0jDeX4bBbql"
      },
      "source": [
        "배추_더미['예측가격'] = ypred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1LkacXGPHxj"
      },
      "source": [
        "배추_더미.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soU3MxO_fFtm"
      },
      "source": [
        "배추_더미['예측가격']=np.expm1(배추_더미['예측가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnrEBIdGPNXa"
      },
      "source": [
        "배추_더미.to_excel('배추_더미(예측완료).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4WHKYo1PuWP"
      },
      "source": [
        "abc = []\r\n",
        "for alg in er.named_estimators:\r\n",
        "    clf = er.named_estimators[alg]\r\n",
        "    a = clf.__class__.__name__\r\n",
        "    b = [pd.DataFrame(sorted(zip(clf.feature_importances_,X_train.columns)), columns=['Value','Feature'])]\r\n",
        "    abc.append({a:b})\r\n",
        "\r\n",
        "abc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu94LBWxsGb6"
      },
      "source": [
        "## hyper_Parameter(상추_시장)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-U3j7duepQq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jZ0iS0osRdE"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTsbAAHSsRdI"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwuipB0vIkg1"
      },
      "source": [
        "상추"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqeYZLwLsRdN"
      },
      "source": [
        "dataset = pd.read_excel('/content/상추_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.rename(columns={'경락가평균가겨':'경락가평균가격'},inplace=True)\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cOu2AB7sRdO"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27cTmzkmBlZD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF-AMQvZ0bb5"
      },
      "source": [
        "dataset2=dataset[['가격','경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "dataset2.head() #위 변수들만 dataset2로 지정 log 변환해줌\r\n",
        "\r\n",
        "dataset2['가격']= np.log1p(dataset2['가격'])\r\n",
        "dataset2['경락가평균가격']= np.log1p(dataset2['경락가평균가격'])\r\n",
        "dataset2['반입량']= np.log1p(dataset2['반입량'])\r\n",
        "dataset2['유가 전국평균가격']= np.log1p(dataset2['유가 전국평균가격'])\r\n",
        "dataset2['도매가격']= np.log1p(dataset2['도매가격'])\r\n",
        "\r\n",
        "dataset1=dataset[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]\r\n",
        "\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "dataset1[:]=scalar.fit_transform(dataset1[:]) #전부다 MinMax로 \r\n",
        "\r\n",
        "dataset=pd.concat([dataset2,dataset1],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydw1lt6DsRdQ"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn5ENVXNsRdQ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu2g4bO3sRdR"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 3)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBAJUEncsRdR"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOvTcx_Bsf4K"
      },
      "source": [
        "#### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lHK1gbwsRdS"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WE7RVj4sRdS"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQvboDodsRdW"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJs7QwgVsRdW"
      },
      "source": [
        "\n",
        "#rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "#rf_parameter\n",
        "\n",
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP456j2psRdW"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.7, \n",
        "                       gamma = 0.1,\n",
        "                       learning_rate = 0.03,\n",
        "                       max_depth = 5,\n",
        "                       min_child_weight = 1,\n",
        "                       n_estimators = 200,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.7)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 7,\n",
        "                               max_features = 3,\n",
        "                               min_samples_leaf = 3,\n",
        "                               min_samples_split = 8,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.7,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.03,\n",
        "                        max_depth = 5,\n",
        "                        min_child_samples = 10,\n",
        "                        n_estimators = 200,\n",
        "                        num_leaves =10,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.01,\n",
        "                                   max_depth=5,\n",
        "                                   n_estimators=200,\n",
        "                                   subsample=0.7\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaBv4DR0sRdX"
      },
      "source": [
        "ypred = rf_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqOHETERsRdY"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2bgFefvsRdY"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\r\n",
        "\r\n",
        "er = VotingRegressor([('xgb_reg', xgb_reg), ('gb_reg', gb_reg),('rf_reg',rf_reg),('lgb_reg',lgb_reg)])\r\n",
        "print(er.fit(X_train, y_train).predict(X_test))\r\n",
        "y_pred = er.fit(X_train, y_train).predict(X_test)\r\n",
        "er.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omy6yBOtsRdY"
      },
      "source": [
        "x_ax = range(len(y_test))\r\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\r\n",
        "plt.plot(x_ax, y_pred, label=\"Predicted Price\")\r\n",
        "plt.title(\"Price Prediction\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF8qBKz4sRdZ"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\r\n",
        "from sklearn.linear_model import RidgeCV\r\n",
        "from sklearn.svm import LinearSVR\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.ensemble import StackingRegressor\r\n",
        "y_target = dataset['가격']\r\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\r\n",
        "estimators= ([('xgb_reg', xgb_reg), ('rf_reg', rf_reg), ('lgb_reg', lgb_reg), ('gb_reg', gb_reg)])\r\n",
        "reg = StackingRegressor(estimators=estimators,final_estimator=RandomForestRegressor(n_estimators=10,random_state=42))\r\n",
        "reg.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gQkEOyCtHDo"
      },
      "source": [
        "#### 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPKb3TnwBxtC"
      },
      "source": [
        "상추_더미= pd.read_excel('/content/상추_더미(예측).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBf2qu-BBxtE"
      },
      "source": [
        "#무_더미['가격']= np.log1p(무_더미['가격'])\r\n",
        "상추_더미['경락가평균가격']= np.log1p(상추_더미['경락가평균가격'])\r\n",
        "상추_더미['반입량']= np.log1p(상추_더미['반입량'])\r\n",
        "상추_더미['유가 전국평균가격']= np.log1p(상추_더미['유가 전국평균가격'])\r\n",
        "상추_더미['도매가격']= np.log1p(상추_더미['도매가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CRWT-WrBxtF"
      },
      "source": [
        "상추_더미1=상추_더미[['경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "상추_더미1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKRkQKxdBxtF"
      },
      "source": [
        "상추_더미2=상추_더미[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXwj7IhIBxtF"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "상추_더미2[:]=scalar.fit_transform(상추_더미2[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDQo34KzBxtG"
      },
      "source": [
        "상추_더미2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCdb2ufqBxtG"
      },
      "source": [
        "상추_더미=pd.concat([상추_더미1,상추_더미2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZXlhc9_BxtH"
      },
      "source": [
        "ypred = er.predict(상추_더미)\r\n",
        "ypred\r\n",
        "#mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usxyZ8Z6Q5ik"
      },
      "source": [
        "상추_더미['예측가격']=ypred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFxIZWdFa7GH"
      },
      "source": [
        "상추_더미['예측가격']=np.expm1(상추_더미['예측가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUESrSpeRxH7"
      },
      "source": [
        "abc = []\r\n",
        "for alg in er.named_estimators:\r\n",
        "    clf = er.named_estimators[alg]\r\n",
        "    a = clf.__class__.__name__\r\n",
        "    b = [pd.DataFrame(sorted(zip(clf.feature_importances_,X_train.columns)), columns=['Value','Feature'])]\r\n",
        "    abc.append({a:b})\r\n",
        "\r\n",
        "abc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReOHh72jtTQs"
      },
      "source": [
        "##hyper_Parameter(오이_시장)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q4hWpDmG2lz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykcvDTFxtfrD"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBf41DpxtfrG"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNnxvQlTtfrH"
      },
      "source": [
        "오이"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmCOeR_UtfrH"
      },
      "source": [
        "dataset = pd.read_excel('/content/오이_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "182_PuuLCZF1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gcdc49oKW-J"
      },
      "source": [
        "dataset2=dataset[['가격','경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "dataset2.head() #위 변수들만 dataset2로 지정 log 변환해줌\r\n",
        "\r\n",
        "dataset2['가격']= np.log1p(dataset2['가격'])\r\n",
        "dataset2['경락가평균가격']= np.log1p(dataset2['경락가평균가격'])\r\n",
        "dataset2['반입량']= np.log1p(dataset2['반입량'])\r\n",
        "dataset2['유가 전국평균가격']= np.log1p(dataset2['유가 전국평균가격'])\r\n",
        "dataset2['도매가격']= np.log1p(dataset2['도매가격'])\r\n",
        "\r\n",
        "dataset1=dataset[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]\r\n",
        "\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "dataset1[:]=scalar.fit_transform(dataset1[:]) #전부다 MinMax로 \r\n",
        "\r\n",
        "dataset=pd.concat([dataset1,dataset2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndoGQ_hitfrH"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwM8et-htfrI"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPI29W7-tfrJ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEDahw40tfrJ"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 3)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIm3AWXKtfrK"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynfN-XAmvj4s"
      },
      "source": [
        "#### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrDqzQWOtfrK"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHjrP9yAtfrL"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_vxzOzwtfrL"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADBedxE-tfrL"
      },
      "source": [
        "\n",
        "#rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "#rf_parameter\n",
        "\n",
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--sgnHMgtfrL"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.5, \n",
        "                       gamma = 0.1,\n",
        "                       learning_rate = 0.01,\n",
        "                       max_depth = 7,\n",
        "                       min_child_weight = 3,\n",
        "                       n_estimators = 500,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.5)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 10,\n",
        "                               max_features = 3,\n",
        "                               min_samples_leaf = 3,\n",
        "                               min_samples_split = 10,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.7,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.03,\n",
        "                        max_depth = 5,\n",
        "                        min_child_samples = 10,\n",
        "                        n_estimators =100,\n",
        "                        num_leaves =10,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.05,\n",
        "                                   max_depth=3,\n",
        "                                   n_estimators=200,\n",
        "                                   subsample=0.5\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs2g1VAstfrL"
      },
      "source": [
        "ypred = rf_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMaDS5PutfrM"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spfQErjutfrM"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\r\n",
        "\r\n",
        "er = VotingRegressor([('xgb_reg', xgb_reg), ('gb_reg', gb_reg)])\r\n",
        "print(er.fit(X_train, y_train).predict(X_test))\r\n",
        "y_pred = er.fit(X_train, y_train).predict(X_test)\r\n",
        "er.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UjoyDhvtfrM"
      },
      "source": [
        "x_ax = range(len(y_test))\r\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\r\n",
        "plt.plot(x_ax, y_pred, label=\"Predicted Price\")\r\n",
        "plt.title(\"Price Prediction\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp_GgZlBtfrM"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\r\n",
        "from sklearn.linear_model import RidgeCV\r\n",
        "from sklearn.svm import LinearSVR\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.ensemble import StackingRegressor\r\n",
        "y_target = dataset['가격']\r\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\r\n",
        "estimators= ([('xgb_reg', xgb_reg), ('rf_reg', rf_reg), ('lgb_reg', lgb_reg), ('gb_reg', gb_reg)])\r\n",
        "reg = StackingRegressor(estimators=estimators,final_estimator=RandomForestRegressor(n_estimators=10,random_state=42))\r\n",
        "reg.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYyD0PxbvreW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYGIPt0cvsWW"
      },
      "source": [
        "#### 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T45o2QQGCkqc"
      },
      "source": [
        "오이_더미= pd.read_excel('/content/오이_더미(예측).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hqUUIK2k6JB"
      },
      "source": [
        "오이_더미.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoVMONhMCkqd"
      },
      "source": [
        "#무_더미['가격']= np.log1p(무_더미['가격'])\r\n",
        "오이_더미['경락가평균가격']= np.log1p(오이_더미['경락가평균가격'])\r\n",
        "오이_더미['반입량']= np.log1p(오이_더미['반입량'])\r\n",
        "오이_더미['유가 전국평균가격']= np.log1p(오이_더미['유가 전국평균가격'])\r\n",
        "오이_더미['도매가격']= np.log1p(오이_더미['도매가격 '])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzTEjKukCkqd"
      },
      "source": [
        "오이_더미1=오이_더미[['경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "오이_더미1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlWLHCsCCkqe"
      },
      "source": [
        "오이_더미2=오이_더미[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxmb_g-8Ckqe"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "오이_더미2[:]=scalar.fit_transform(오이_더미2[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT6GM70xCkqf"
      },
      "source": [
        "오이_더미2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi27ElZZCkqf"
      },
      "source": [
        "오이_더미=pd.concat([오이_더미2,오이_더미1],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yY872yjAvcg"
      },
      "source": [
        "오이_더미"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyO964SwCkqj"
      },
      "source": [
        "ypred = gb_reg.predict(오이_더미)\r\n",
        "ypred\r\n",
        "#mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-wqO5_ICkqk"
      },
      "source": [
        "오이_더미['예측가격'] = ypred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LVDZxuzCmXs"
      },
      "source": [
        "오이_더미"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I-GgdW0Ckqm"
      },
      "source": [
        "오이_더미['예측가격']=np.expm1(오이_더미['예측가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W2wCNvRlPgD"
      },
      "source": [
        "오이_더미"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-xgtKq3Ckqn"
      },
      "source": [
        "오이_더미.to_excel('오이_더미(예측완료).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSEbK_zhTP2D"
      },
      "source": [
        "pd.DataFrame(sorted(zip(gb_reg.feature_importances_,X_train.columns)), columns=['Value','Feature'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEIBi65wv6PM"
      },
      "source": [
        "##hyper_Parameter(양파_시장)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gepJ1zknwVtn"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGWsvopWmUQD"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgyAPv-nmUQD"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZAfg6M9mUQD"
      },
      "source": [
        "양파"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOYfauNmmUQD"
      },
      "source": [
        "dataset = pd.read_excel('/content/양파_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn9YDt0dB-Nu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvkVtHttnroP"
      },
      "source": [
        "dataset2=dataset[['가격','경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "dataset2.head() #위 변수들만 dataset2로 지정 log 변환해줌\r\n",
        "\r\n",
        "dataset2['가격']= np.log1p(dataset2['가격'])\r\n",
        "dataset2['경락가평균가격']= np.log1p(dataset2['경락가평균가격'])\r\n",
        "dataset2['반입량']= np.log1p(dataset2['반입량'])\r\n",
        "dataset2['유가 전국평균가격']= np.log1p(dataset2['유가 전국평균가격'])\r\n",
        "dataset2['도매가격']= np.log1p(dataset2['도매가격'])\r\n",
        "\r\n",
        "dataset1=dataset[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]\r\n",
        "\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "dataset1[:]=scalar.fit_transform(dataset1[:]) #전부다 MinMax로 \r\n",
        "\r\n",
        "dataset=pd.concat([dataset1,dataset2],axis=1)\r\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMPAoHND2NZQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSfTiPoj4FzS"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq5GtUzt2MM2"
      },
      "source": [
        "#sns.distplot(y_target, rug=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVvdDXY036Rp"
      },
      "source": [
        "#dataset['가격']=np.log1p(dataset['가격'])\r\n",
        "#sns.distplot(dataset['가격'],fit=norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zNFlUZXmUQD"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc2h5wGpmUQD"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 3)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WybAl1BbmUQD"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-nZ0nXjwgFA"
      },
      "source": [
        "#### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xjD6MPsmUQE"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPThK-PDmUQE"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGThKhOqmUQE"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRmNzlcemUQE"
      },
      "source": [
        "\n",
        "#rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "#rf_parameter\n",
        "\n",
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTzlxpgqmUQE"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.5, \n",
        "                       gamma = 0.1,\n",
        "                       learning_rate = 0.01,\n",
        "                       max_depth = 3,\n",
        "                       min_child_weight = 5,\n",
        "                       n_estimators = 500,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.5)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 7,\n",
        "                               max_features = 2,\n",
        "                               min_samples_leaf = 5,\n",
        "                               min_samples_split = 12,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.5,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.01,\n",
        "                        max_depth = 5,\n",
        "                        min_child_samples = 10,\n",
        "                        n_estimators = 200,\n",
        "                        num_leaves =6,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.01,\n",
        "                                   max_depth=3,\n",
        "                                   n_estimators=200,\n",
        "                                   subsample=0.5\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU9g_knImUQE"
      },
      "source": [
        "ypred = rf_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsXw96ZTmUQE"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72I0XwsmmUQE"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "#rf_reg = RandomForestRegressor(random_state=0, \n",
        "#                              bootstrap = [True],\n",
        "#                              max_depth = 7,\n",
        "#                              max_features = 2,\n",
        "#                               min_samples_leaf = 5,\n",
        "#                               min_samples_split = 12,\n",
        "#                               n_estimators = 100\n",
        "#                               )\n",
        "\n",
        "#gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "#                                   learning_rate=0.01,\n",
        "#                                   max_depth=3,\n",
        "#                                   n_estimators=200,\n",
        "#                                   subsample=0.5\n",
        "#                                   )\n",
        "er = VotingRegressor([('xgb_reg', xgb_reg), ('rf_reg', rf_reg)])\n",
        "print(er.fit(X_train, y_train).predict(X_test))\n",
        "y_pred = er.fit(X_train, y_train).predict(X_test)\n",
        "er.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN-B8UOCmUQE"
      },
      "source": [
        "#y_pred = er.fit(X_data, y_target).predict(X_data) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5d-dxnymUQE"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, y_pred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo7Pj9d0OJoQ"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "estimators= ([('xgb_reg', xgb_reg), ('rf_reg', rf_reg), ('lgb_reg', lgb_reg), ('gb_reg', gb_reg)])\n",
        "reg = StackingRegressor(estimators=estimators,final_estimator=RandomForestRegressor(n_estimators=10,random_state=42))\n",
        "reg.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5hxVZNwwl-z"
      },
      "source": [
        "#### 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpza3fEmCR9y"
      },
      "source": [
        "양파_더미= pd.read_excel('/content/양파_더미(예측).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xpxTffbCR9z"
      },
      "source": [
        "#무_더미['가격']= np.log1p(무_더미['가격'])\r\n",
        "양파_더미['경락가평균가격']= np.log1p(양파_더미['경락가평균가격'])\r\n",
        "양파_더미['반입량']= np.log1p(양파_더미['반입량'])\r\n",
        "양파_더미['유가 전국평균가격']= np.log1p(양파_더미['유가 전국평균가격'])\r\n",
        "양파_더미['도매가격']= np.log1p(양파_더미['도매가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTRGDxAECR90"
      },
      "source": [
        "양파_더미1=양파_더미[['경락가평균가격','반입량','유가 전국평균가격','도매가격']]\r\n",
        "양파_더미1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_cjOhsoCR91"
      },
      "source": [
        "양파_더미2=양파_더미[['유무','최저기온(°C)','최고기온(°C)','일강수량(mm)']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3P7p8YqCR92"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scalar=MinMaxScaler()\r\n",
        "양파_더미2[:]=scalar.fit_transform(양파_더미2[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unS09qBOCR92"
      },
      "source": [
        "양파_더미2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JggV2X3-CR93"
      },
      "source": [
        "양파_더미=pd.concat([양파_더미2,양파_더미1],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Sv3TCZiYRC"
      },
      "source": [
        "양파_더미"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuLrAXYkCR94"
      },
      "source": [
        "ypred = er.predict(양파_더미)\r\n",
        "ypred\r\n",
        "#mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6-7tDCaijbV"
      },
      "source": [
        "양파_더미['예측가격'] = ypred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFQWhw7silnO"
      },
      "source": [
        "양파_더미"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdwgJbVvisFz"
      },
      "source": [
        "양파_더미['예측가격']=np.expm1(양파_더미['예측가격'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRW2Ed7-iujV"
      },
      "source": [
        "양파_더미"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjpZM0PnixoJ"
      },
      "source": [
        "양파_더미.to_excel('양파_더미(예측완료).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss7g6_iCUjmS"
      },
      "source": [
        "abc = []\r\n",
        "for alg in er.named_estimators:\r\n",
        "    clf = er.named_estimators[alg]\r\n",
        "    a = clf.__class__.__name__\r\n",
        "    b = [pd.DataFrame(sorted(zip(clf.feature_importances_,X_train.columns)), columns=['Value','Feature'])]\r\n",
        "    abc.append({a:b})\r\n",
        "\r\n",
        "abc"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}